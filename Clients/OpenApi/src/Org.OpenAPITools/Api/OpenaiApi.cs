// <auto-generated>
/*
 * Open WebUI
 *
 * No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)
 *
 * The version of the OpenAPI document: 0.1.0
 * Generated by: https://github.com/openapitools/openapi-generator.git
 */

#nullable enable

using System;
using System.Collections.Generic;
using System.Net;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using System.Net.Http;
using System.Net.Http.Headers;
using System.Text.Json;
using Org.OpenAPITools.Client;
using Org.OpenAPITools.Model;
using System.Diagnostics.CodeAnalysis;

namespace Org.OpenAPITools.Api
{
    /// <summary>
    /// Represents a collection of functions to interact with the API endpoints
    /// This class is registered as transient.
    /// </summary>
    public interface IOpenaiApi : IApi
    {
        /// <summary>
        /// The class containing the events
        /// </summary>
        OpenaiApiEvents Events { get; }

        /// <summary>
        /// Generate Chat Completion
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="body"></param>
        /// <param name="bypassFilter"> (optional)</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGenerateChatCompletionOpenaiChatCompletionsPostApiResponse"/>&gt;</returns>
        Task<IGenerateChatCompletionOpenaiChatCompletionsPostApiResponse> GenerateChatCompletionOpenaiChatCompletionsPostAsync(Object body, Option<bool?> bypassFilter = default, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Generate Chat Completion
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <param name="body"></param>
        /// <param name="bypassFilter"> (optional)</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGenerateChatCompletionOpenaiChatCompletionsPostApiResponse"/>?&gt;</returns>
        Task<IGenerateChatCompletionOpenaiChatCompletionsPostApiResponse?> GenerateChatCompletionOpenaiChatCompletionsPostOrDefaultAsync(Object body, Option<bool?> bypassFilter = default, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Get Config
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGetConfigOpenaiConfigGetApiResponse"/>&gt;</returns>
        Task<IGetConfigOpenaiConfigGetApiResponse> GetConfigOpenaiConfigGetAsync(System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Get Config
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGetConfigOpenaiConfigGetApiResponse"/>?&gt;</returns>
        Task<IGetConfigOpenaiConfigGetApiResponse?> GetConfigOpenaiConfigGetOrDefaultAsync(System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Get Models
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="urlIdx"> (optional)</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGetModelsOpenaiModelsGetApiResponse"/>&gt;</returns>
        Task<IGetModelsOpenaiModelsGetApiResponse> GetModelsOpenaiModelsGetAsync(Option<int?> urlIdx = default, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Get Models
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <param name="urlIdx"> (optional)</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGetModelsOpenaiModelsGetApiResponse"/>?&gt;</returns>
        Task<IGetModelsOpenaiModelsGetApiResponse?> GetModelsOpenaiModelsGetOrDefaultAsync(Option<int?> urlIdx = default, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Get Models
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="urlIdx"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGetModelsOpenaiModelsUrlIdxGetApiResponse"/>&gt;</returns>
        Task<IGetModelsOpenaiModelsUrlIdxGetApiResponse> GetModelsOpenaiModelsUrlIdxGetAsync(int? urlIdx = default, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Get Models
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <param name="urlIdx"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGetModelsOpenaiModelsUrlIdxGetApiResponse"/>?&gt;</returns>
        Task<IGetModelsOpenaiModelsUrlIdxGetApiResponse?> GetModelsOpenaiModelsUrlIdxGetOrDefaultAsync(int? urlIdx = default, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Proxy
        /// </summary>
        /// <remarks>
        /// Deprecated: proxy all requests to OpenAI API
        /// </remarks>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDeleteApiResponse"/>&gt;</returns>
        Task<IProxyOpenaiPathDeleteApiResponse> ProxyOpenaiPathDeleteAsync(string path, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Proxy
        /// </summary>
        /// <remarks>
        /// Deprecated: proxy all requests to OpenAI API
        /// </remarks>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDeleteApiResponse"/>?&gt;</returns>
        Task<IProxyOpenaiPathDeleteApiResponse?> ProxyOpenaiPathDeleteOrDefaultAsync(string path, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Proxy
        /// </summary>
        /// <remarks>
        /// Deprecated: proxy all requests to OpenAI API
        /// </remarks>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDelete_0ApiResponse"/>&gt;</returns>
        Task<IProxyOpenaiPathDelete_0ApiResponse> ProxyOpenaiPathDelete_0Async(string path, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Proxy
        /// </summary>
        /// <remarks>
        /// Deprecated: proxy all requests to OpenAI API
        /// </remarks>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDelete_0ApiResponse"/>?&gt;</returns>
        Task<IProxyOpenaiPathDelete_0ApiResponse?> ProxyOpenaiPathDelete_0OrDefaultAsync(string path, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Proxy
        /// </summary>
        /// <remarks>
        /// Deprecated: proxy all requests to OpenAI API
        /// </remarks>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDelete_1ApiResponse"/>&gt;</returns>
        Task<IProxyOpenaiPathDelete_1ApiResponse> ProxyOpenaiPathDelete_1Async(string path, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Proxy
        /// </summary>
        /// <remarks>
        /// Deprecated: proxy all requests to OpenAI API
        /// </remarks>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDelete_1ApiResponse"/>?&gt;</returns>
        Task<IProxyOpenaiPathDelete_1ApiResponse?> ProxyOpenaiPathDelete_1OrDefaultAsync(string path, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Proxy
        /// </summary>
        /// <remarks>
        /// Deprecated: proxy all requests to OpenAI API
        /// </remarks>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDelete_2ApiResponse"/>&gt;</returns>
        Task<IProxyOpenaiPathDelete_2ApiResponse> ProxyOpenaiPathDelete_2Async(string path, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Proxy
        /// </summary>
        /// <remarks>
        /// Deprecated: proxy all requests to OpenAI API
        /// </remarks>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDelete_2ApiResponse"/>?&gt;</returns>
        Task<IProxyOpenaiPathDelete_2ApiResponse?> ProxyOpenaiPathDelete_2OrDefaultAsync(string path, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Speech
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="ISpeechOpenaiAudioSpeechPostApiResponse"/>&gt;</returns>
        Task<ISpeechOpenaiAudioSpeechPostApiResponse> SpeechOpenaiAudioSpeechPostAsync(System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Speech
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="ISpeechOpenaiAudioSpeechPostApiResponse"/>?&gt;</returns>
        Task<ISpeechOpenaiAudioSpeechPostApiResponse?> SpeechOpenaiAudioSpeechPostOrDefaultAsync(System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Update Config
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="openWebuiRoutersOpenaiOpenAIConfigForm"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IUpdateConfigOpenaiConfigUpdatePostApiResponse"/>&gt;</returns>
        Task<IUpdateConfigOpenaiConfigUpdatePostApiResponse> UpdateConfigOpenaiConfigUpdatePostAsync(OpenWebuiRoutersOpenaiOpenAIConfigForm openWebuiRoutersOpenaiOpenAIConfigForm, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Update Config
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <param name="openWebuiRoutersOpenaiOpenAIConfigForm"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IUpdateConfigOpenaiConfigUpdatePostApiResponse"/>?&gt;</returns>
        Task<IUpdateConfigOpenaiConfigUpdatePostApiResponse?> UpdateConfigOpenaiConfigUpdatePostOrDefaultAsync(OpenWebuiRoutersOpenaiOpenAIConfigForm openWebuiRoutersOpenaiOpenAIConfigForm, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Verify Connection
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="openWebuiRoutersOpenaiConnectionVerificationForm"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IVerifyConnectionOpenaiVerifyPostApiResponse"/>&gt;</returns>
        Task<IVerifyConnectionOpenaiVerifyPostApiResponse> VerifyConnectionOpenaiVerifyPostAsync(OpenWebuiRoutersOpenaiConnectionVerificationForm openWebuiRoutersOpenaiConnectionVerificationForm, System.Threading.CancellationToken cancellationToken = default);

        /// <summary>
        /// Verify Connection
        /// </summary>
        /// <remarks>
        /// 
        /// </remarks>
        /// <param name="openWebuiRoutersOpenaiConnectionVerificationForm"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IVerifyConnectionOpenaiVerifyPostApiResponse"/>?&gt;</returns>
        Task<IVerifyConnectionOpenaiVerifyPostApiResponse?> VerifyConnectionOpenaiVerifyPostOrDefaultAsync(OpenWebuiRoutersOpenaiConnectionVerificationForm openWebuiRoutersOpenaiConnectionVerificationForm, System.Threading.CancellationToken cancellationToken = default);
    }

    /// <summary>
    /// The <see cref="IGenerateChatCompletionOpenaiChatCompletionsPostApiResponse"/>
    /// </summary>
    public interface IGenerateChatCompletionOpenaiChatCompletionsPostApiResponse : Org.OpenAPITools.Client.IApiResponse, IOk<Object?>, IUnprocessableContent<Org.OpenAPITools.Model.HTTPValidationError?>
    {
        /// <summary>
        /// Returns true if the response is 200 Ok
        /// </summary>
        /// <returns></returns>
        bool IsOk { get; }

        /// <summary>
        /// Returns true if the response is 422 UnprocessableContent
        /// </summary>
        /// <returns></returns>
        bool IsUnprocessableContent { get; }
    }

    /// <summary>
    /// The <see cref="IGetConfigOpenaiConfigGetApiResponse"/>
    /// </summary>
    public interface IGetConfigOpenaiConfigGetApiResponse : Org.OpenAPITools.Client.IApiResponse, IOk<Object?>
    {
        /// <summary>
        /// Returns true if the response is 200 Ok
        /// </summary>
        /// <returns></returns>
        bool IsOk { get; }
    }

    /// <summary>
    /// The <see cref="IGetModelsOpenaiModelsGetApiResponse"/>
    /// </summary>
    public interface IGetModelsOpenaiModelsGetApiResponse : Org.OpenAPITools.Client.IApiResponse, IOk<Object?>, IUnprocessableContent<Org.OpenAPITools.Model.HTTPValidationError?>
    {
        /// <summary>
        /// Returns true if the response is 200 Ok
        /// </summary>
        /// <returns></returns>
        bool IsOk { get; }

        /// <summary>
        /// Returns true if the response is 422 UnprocessableContent
        /// </summary>
        /// <returns></returns>
        bool IsUnprocessableContent { get; }
    }

    /// <summary>
    /// The <see cref="IGetModelsOpenaiModelsUrlIdxGetApiResponse"/>
    /// </summary>
    public interface IGetModelsOpenaiModelsUrlIdxGetApiResponse : Org.OpenAPITools.Client.IApiResponse, IOk<Object?>, IUnprocessableContent<Org.OpenAPITools.Model.HTTPValidationError?>
    {
        /// <summary>
        /// Returns true if the response is 200 Ok
        /// </summary>
        /// <returns></returns>
        bool IsOk { get; }

        /// <summary>
        /// Returns true if the response is 422 UnprocessableContent
        /// </summary>
        /// <returns></returns>
        bool IsUnprocessableContent { get; }
    }

    /// <summary>
    /// The <see cref="IProxyOpenaiPathDeleteApiResponse"/>
    /// </summary>
    public interface IProxyOpenaiPathDeleteApiResponse : Org.OpenAPITools.Client.IApiResponse, IOk<Object?>, IUnprocessableContent<Org.OpenAPITools.Model.HTTPValidationError?>
    {
        /// <summary>
        /// Returns true if the response is 200 Ok
        /// </summary>
        /// <returns></returns>
        bool IsOk { get; }

        /// <summary>
        /// Returns true if the response is 422 UnprocessableContent
        /// </summary>
        /// <returns></returns>
        bool IsUnprocessableContent { get; }
    }

    /// <summary>
    /// The <see cref="IProxyOpenaiPathDelete_0ApiResponse"/>
    /// </summary>
    public interface IProxyOpenaiPathDelete_0ApiResponse : Org.OpenAPITools.Client.IApiResponse, IOk<Object?>, IUnprocessableContent<Org.OpenAPITools.Model.HTTPValidationError?>
    {
        /// <summary>
        /// Returns true if the response is 200 Ok
        /// </summary>
        /// <returns></returns>
        bool IsOk { get; }

        /// <summary>
        /// Returns true if the response is 422 UnprocessableContent
        /// </summary>
        /// <returns></returns>
        bool IsUnprocessableContent { get; }
    }

    /// <summary>
    /// The <see cref="IProxyOpenaiPathDelete_1ApiResponse"/>
    /// </summary>
    public interface IProxyOpenaiPathDelete_1ApiResponse : Org.OpenAPITools.Client.IApiResponse, IOk<Object?>, IUnprocessableContent<Org.OpenAPITools.Model.HTTPValidationError?>
    {
        /// <summary>
        /// Returns true if the response is 200 Ok
        /// </summary>
        /// <returns></returns>
        bool IsOk { get; }

        /// <summary>
        /// Returns true if the response is 422 UnprocessableContent
        /// </summary>
        /// <returns></returns>
        bool IsUnprocessableContent { get; }
    }

    /// <summary>
    /// The <see cref="IProxyOpenaiPathDelete_2ApiResponse"/>
    /// </summary>
    public interface IProxyOpenaiPathDelete_2ApiResponse : Org.OpenAPITools.Client.IApiResponse, IOk<Object?>, IUnprocessableContent<Org.OpenAPITools.Model.HTTPValidationError?>
    {
        /// <summary>
        /// Returns true if the response is 200 Ok
        /// </summary>
        /// <returns></returns>
        bool IsOk { get; }

        /// <summary>
        /// Returns true if the response is 422 UnprocessableContent
        /// </summary>
        /// <returns></returns>
        bool IsUnprocessableContent { get; }
    }

    /// <summary>
    /// The <see cref="ISpeechOpenaiAudioSpeechPostApiResponse"/>
    /// </summary>
    public interface ISpeechOpenaiAudioSpeechPostApiResponse : Org.OpenAPITools.Client.IApiResponse, IOk<Object?>
    {
        /// <summary>
        /// Returns true if the response is 200 Ok
        /// </summary>
        /// <returns></returns>
        bool IsOk { get; }
    }

    /// <summary>
    /// The <see cref="IUpdateConfigOpenaiConfigUpdatePostApiResponse"/>
    /// </summary>
    public interface IUpdateConfigOpenaiConfigUpdatePostApiResponse : Org.OpenAPITools.Client.IApiResponse, IOk<Object?>, IUnprocessableContent<Org.OpenAPITools.Model.HTTPValidationError?>
    {
        /// <summary>
        /// Returns true if the response is 200 Ok
        /// </summary>
        /// <returns></returns>
        bool IsOk { get; }

        /// <summary>
        /// Returns true if the response is 422 UnprocessableContent
        /// </summary>
        /// <returns></returns>
        bool IsUnprocessableContent { get; }
    }

    /// <summary>
    /// The <see cref="IVerifyConnectionOpenaiVerifyPostApiResponse"/>
    /// </summary>
    public interface IVerifyConnectionOpenaiVerifyPostApiResponse : Org.OpenAPITools.Client.IApiResponse, IOk<Object?>, IUnprocessableContent<Org.OpenAPITools.Model.HTTPValidationError?>
    {
        /// <summary>
        /// Returns true if the response is 200 Ok
        /// </summary>
        /// <returns></returns>
        bool IsOk { get; }

        /// <summary>
        /// Returns true if the response is 422 UnprocessableContent
        /// </summary>
        /// <returns></returns>
        bool IsUnprocessableContent { get; }
    }

    /// <summary>
    /// Represents a collection of functions to interact with the API endpoints
    /// </summary>
    public class OpenaiApiEvents
    {
        /// <summary>
        /// The event raised after the server response
        /// </summary>
        public event EventHandler<ApiResponseEventArgs>? OnGenerateChatCompletionOpenaiChatCompletionsPost;

        /// <summary>
        /// The event raised after an error querying the server
        /// </summary>
        public event EventHandler<ExceptionEventArgs>? OnErrorGenerateChatCompletionOpenaiChatCompletionsPost;

        internal void ExecuteOnGenerateChatCompletionOpenaiChatCompletionsPost(OpenaiApi.GenerateChatCompletionOpenaiChatCompletionsPostApiResponse apiResponse)
        {
            OnGenerateChatCompletionOpenaiChatCompletionsPost?.Invoke(this, new ApiResponseEventArgs(apiResponse));
        }

        internal void ExecuteOnErrorGenerateChatCompletionOpenaiChatCompletionsPost(Exception exception)
        {
            OnErrorGenerateChatCompletionOpenaiChatCompletionsPost?.Invoke(this, new ExceptionEventArgs(exception));
        }

        /// <summary>
        /// The event raised after the server response
        /// </summary>
        public event EventHandler<ApiResponseEventArgs>? OnGetConfigOpenaiConfigGet;

        /// <summary>
        /// The event raised after an error querying the server
        /// </summary>
        public event EventHandler<ExceptionEventArgs>? OnErrorGetConfigOpenaiConfigGet;

        internal void ExecuteOnGetConfigOpenaiConfigGet(OpenaiApi.GetConfigOpenaiConfigGetApiResponse apiResponse)
        {
            OnGetConfigOpenaiConfigGet?.Invoke(this, new ApiResponseEventArgs(apiResponse));
        }

        internal void ExecuteOnErrorGetConfigOpenaiConfigGet(Exception exception)
        {
            OnErrorGetConfigOpenaiConfigGet?.Invoke(this, new ExceptionEventArgs(exception));
        }

        /// <summary>
        /// The event raised after the server response
        /// </summary>
        public event EventHandler<ApiResponseEventArgs>? OnGetModelsOpenaiModelsGet;

        /// <summary>
        /// The event raised after an error querying the server
        /// </summary>
        public event EventHandler<ExceptionEventArgs>? OnErrorGetModelsOpenaiModelsGet;

        internal void ExecuteOnGetModelsOpenaiModelsGet(OpenaiApi.GetModelsOpenaiModelsGetApiResponse apiResponse)
        {
            OnGetModelsOpenaiModelsGet?.Invoke(this, new ApiResponseEventArgs(apiResponse));
        }

        internal void ExecuteOnErrorGetModelsOpenaiModelsGet(Exception exception)
        {
            OnErrorGetModelsOpenaiModelsGet?.Invoke(this, new ExceptionEventArgs(exception));
        }

        /// <summary>
        /// The event raised after the server response
        /// </summary>
        public event EventHandler<ApiResponseEventArgs>? OnGetModelsOpenaiModelsUrlIdxGet;

        /// <summary>
        /// The event raised after an error querying the server
        /// </summary>
        public event EventHandler<ExceptionEventArgs>? OnErrorGetModelsOpenaiModelsUrlIdxGet;

        internal void ExecuteOnGetModelsOpenaiModelsUrlIdxGet(OpenaiApi.GetModelsOpenaiModelsUrlIdxGetApiResponse apiResponse)
        {
            OnGetModelsOpenaiModelsUrlIdxGet?.Invoke(this, new ApiResponseEventArgs(apiResponse));
        }

        internal void ExecuteOnErrorGetModelsOpenaiModelsUrlIdxGet(Exception exception)
        {
            OnErrorGetModelsOpenaiModelsUrlIdxGet?.Invoke(this, new ExceptionEventArgs(exception));
        }

        /// <summary>
        /// The event raised after the server response
        /// </summary>
        public event EventHandler<ApiResponseEventArgs>? OnProxyOpenaiPathDelete;

        /// <summary>
        /// The event raised after an error querying the server
        /// </summary>
        public event EventHandler<ExceptionEventArgs>? OnErrorProxyOpenaiPathDelete;

        internal void ExecuteOnProxyOpenaiPathDelete(OpenaiApi.ProxyOpenaiPathDeleteApiResponse apiResponse)
        {
            OnProxyOpenaiPathDelete?.Invoke(this, new ApiResponseEventArgs(apiResponse));
        }

        internal void ExecuteOnErrorProxyOpenaiPathDelete(Exception exception)
        {
            OnErrorProxyOpenaiPathDelete?.Invoke(this, new ExceptionEventArgs(exception));
        }

        /// <summary>
        /// The event raised after the server response
        /// </summary>
        public event EventHandler<ApiResponseEventArgs>? OnProxyOpenaiPathDelete_0;

        /// <summary>
        /// The event raised after an error querying the server
        /// </summary>
        public event EventHandler<ExceptionEventArgs>? OnErrorProxyOpenaiPathDelete_0;

        internal void ExecuteOnProxyOpenaiPathDelete_0(OpenaiApi.ProxyOpenaiPathDelete_0ApiResponse apiResponse)
        {
            OnProxyOpenaiPathDelete_0?.Invoke(this, new ApiResponseEventArgs(apiResponse));
        }

        internal void ExecuteOnErrorProxyOpenaiPathDelete_0(Exception exception)
        {
            OnErrorProxyOpenaiPathDelete_0?.Invoke(this, new ExceptionEventArgs(exception));
        }

        /// <summary>
        /// The event raised after the server response
        /// </summary>
        public event EventHandler<ApiResponseEventArgs>? OnProxyOpenaiPathDelete_1;

        /// <summary>
        /// The event raised after an error querying the server
        /// </summary>
        public event EventHandler<ExceptionEventArgs>? OnErrorProxyOpenaiPathDelete_1;

        internal void ExecuteOnProxyOpenaiPathDelete_1(OpenaiApi.ProxyOpenaiPathDelete_1ApiResponse apiResponse)
        {
            OnProxyOpenaiPathDelete_1?.Invoke(this, new ApiResponseEventArgs(apiResponse));
        }

        internal void ExecuteOnErrorProxyOpenaiPathDelete_1(Exception exception)
        {
            OnErrorProxyOpenaiPathDelete_1?.Invoke(this, new ExceptionEventArgs(exception));
        }

        /// <summary>
        /// The event raised after the server response
        /// </summary>
        public event EventHandler<ApiResponseEventArgs>? OnProxyOpenaiPathDelete_2;

        /// <summary>
        /// The event raised after an error querying the server
        /// </summary>
        public event EventHandler<ExceptionEventArgs>? OnErrorProxyOpenaiPathDelete_2;

        internal void ExecuteOnProxyOpenaiPathDelete_2(OpenaiApi.ProxyOpenaiPathDelete_2ApiResponse apiResponse)
        {
            OnProxyOpenaiPathDelete_2?.Invoke(this, new ApiResponseEventArgs(apiResponse));
        }

        internal void ExecuteOnErrorProxyOpenaiPathDelete_2(Exception exception)
        {
            OnErrorProxyOpenaiPathDelete_2?.Invoke(this, new ExceptionEventArgs(exception));
        }

        /// <summary>
        /// The event raised after the server response
        /// </summary>
        public event EventHandler<ApiResponseEventArgs>? OnSpeechOpenaiAudioSpeechPost;

        /// <summary>
        /// The event raised after an error querying the server
        /// </summary>
        public event EventHandler<ExceptionEventArgs>? OnErrorSpeechOpenaiAudioSpeechPost;

        internal void ExecuteOnSpeechOpenaiAudioSpeechPost(OpenaiApi.SpeechOpenaiAudioSpeechPostApiResponse apiResponse)
        {
            OnSpeechOpenaiAudioSpeechPost?.Invoke(this, new ApiResponseEventArgs(apiResponse));
        }

        internal void ExecuteOnErrorSpeechOpenaiAudioSpeechPost(Exception exception)
        {
            OnErrorSpeechOpenaiAudioSpeechPost?.Invoke(this, new ExceptionEventArgs(exception));
        }

        /// <summary>
        /// The event raised after the server response
        /// </summary>
        public event EventHandler<ApiResponseEventArgs>? OnUpdateConfigOpenaiConfigUpdatePost;

        /// <summary>
        /// The event raised after an error querying the server
        /// </summary>
        public event EventHandler<ExceptionEventArgs>? OnErrorUpdateConfigOpenaiConfigUpdatePost;

        internal void ExecuteOnUpdateConfigOpenaiConfigUpdatePost(OpenaiApi.UpdateConfigOpenaiConfigUpdatePostApiResponse apiResponse)
        {
            OnUpdateConfigOpenaiConfigUpdatePost?.Invoke(this, new ApiResponseEventArgs(apiResponse));
        }

        internal void ExecuteOnErrorUpdateConfigOpenaiConfigUpdatePost(Exception exception)
        {
            OnErrorUpdateConfigOpenaiConfigUpdatePost?.Invoke(this, new ExceptionEventArgs(exception));
        }

        /// <summary>
        /// The event raised after the server response
        /// </summary>
        public event EventHandler<ApiResponseEventArgs>? OnVerifyConnectionOpenaiVerifyPost;

        /// <summary>
        /// The event raised after an error querying the server
        /// </summary>
        public event EventHandler<ExceptionEventArgs>? OnErrorVerifyConnectionOpenaiVerifyPost;

        internal void ExecuteOnVerifyConnectionOpenaiVerifyPost(OpenaiApi.VerifyConnectionOpenaiVerifyPostApiResponse apiResponse)
        {
            OnVerifyConnectionOpenaiVerifyPost?.Invoke(this, new ApiResponseEventArgs(apiResponse));
        }

        internal void ExecuteOnErrorVerifyConnectionOpenaiVerifyPost(Exception exception)
        {
            OnErrorVerifyConnectionOpenaiVerifyPost?.Invoke(this, new ExceptionEventArgs(exception));
        }
    }

    /// <summary>
    /// Represents a collection of functions to interact with the API endpoints
    /// </summary>
    public sealed partial class OpenaiApi : IOpenaiApi
    {
        private JsonSerializerOptions _jsonSerializerOptions;

        /// <summary>
        /// The logger factory
        /// </summary>
        public ILoggerFactory LoggerFactory { get; }

        /// <summary>
        /// The logger
        /// </summary>
        public ILogger<OpenaiApi> Logger { get; }

        /// <summary>
        /// The HttpClient
        /// </summary>
        public HttpClient HttpClient { get; }

        /// <summary>
        /// The class containing the events
        /// </summary>
        public OpenaiApiEvents Events { get; }

        /// <summary>
        /// A token provider of type <see cref="BearerToken"/>
        /// </summary>
        public TokenProvider<BearerToken> BearerTokenProvider { get; }

        /// <summary>
        /// Initializes a new instance of the <see cref="OpenaiApi"/> class.
        /// </summary>
        /// <returns></returns>
        public OpenaiApi(ILogger<OpenaiApi> logger, ILoggerFactory loggerFactory, HttpClient httpClient, JsonSerializerOptionsProvider jsonSerializerOptionsProvider, OpenaiApiEvents openaiApiEvents,
            TokenProvider<BearerToken> bearerTokenProvider)
        {
            _jsonSerializerOptions = jsonSerializerOptionsProvider.Options;
            LoggerFactory = loggerFactory;
            Logger = LoggerFactory.CreateLogger<OpenaiApi>();
            HttpClient = httpClient;
            Events = openaiApiEvents;
            BearerTokenProvider = bearerTokenProvider;
        }

        partial void FormatGenerateChatCompletionOpenaiChatCompletionsPost(ref Object body, ref Option<bool?> bypassFilter);

        /// <summary>
        /// Validates the request parameters
        /// </summary>
        /// <param name="body"></param>
        /// <returns></returns>
        private void ValidateGenerateChatCompletionOpenaiChatCompletionsPost(Object body)
        {
            if (body == null)
                throw new ArgumentNullException(nameof(body));
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="body"></param>
        /// <param name="bypassFilter"></param>
        private void AfterGenerateChatCompletionOpenaiChatCompletionsPostDefaultImplementation(IGenerateChatCompletionOpenaiChatCompletionsPostApiResponse apiResponseLocalVar, Object body, Option<bool?> bypassFilter)
        {
            bool suppressDefaultLog = false;
            AfterGenerateChatCompletionOpenaiChatCompletionsPost(ref suppressDefaultLog, apiResponseLocalVar, body, bypassFilter);
            if (!suppressDefaultLog)
                Logger.LogInformation("{0,-9} | {1} | {3}", (apiResponseLocalVar.DownloadedAt - apiResponseLocalVar.RequestedAt).TotalSeconds, apiResponseLocalVar.StatusCode, apiResponseLocalVar.Path);
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="suppressDefaultLog"></param>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="body"></param>
        /// <param name="bypassFilter"></param>
        partial void AfterGenerateChatCompletionOpenaiChatCompletionsPost(ref bool suppressDefaultLog, IGenerateChatCompletionOpenaiChatCompletionsPostApiResponse apiResponseLocalVar, Object body, Option<bool?> bypassFilter);

        /// <summary>
        /// Logs exceptions that occur while retrieving the server response
        /// </summary>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="body"></param>
        /// <param name="bypassFilter"></param>
        private void OnErrorGenerateChatCompletionOpenaiChatCompletionsPostDefaultImplementation(Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, Object body, Option<bool?> bypassFilter)
        {
            bool suppressDefaultLogLocalVar = false;
            OnErrorGenerateChatCompletionOpenaiChatCompletionsPost(ref suppressDefaultLogLocalVar, exceptionLocalVar, pathFormatLocalVar, pathLocalVar, body, bypassFilter);
            if (!suppressDefaultLogLocalVar)
                Logger.LogError(exceptionLocalVar, "An error occurred while sending the request to the server.");
        }

        /// <summary>
        /// A partial method that gives developers a way to provide customized exception handling
        /// </summary>
        /// <param name="suppressDefaultLogLocalVar"></param>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="body"></param>
        /// <param name="bypassFilter"></param>
        partial void OnErrorGenerateChatCompletionOpenaiChatCompletionsPost(ref bool suppressDefaultLogLocalVar, Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, Object body, Option<bool?> bypassFilter);

        /// <summary>
        /// Generate Chat Completion 
        /// </summary>
        /// <param name="body"></param>
        /// <param name="bypassFilter"> (optional)</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGenerateChatCompletionOpenaiChatCompletionsPostApiResponse"/>&gt;</returns>
        public async Task<IGenerateChatCompletionOpenaiChatCompletionsPostApiResponse?> GenerateChatCompletionOpenaiChatCompletionsPostOrDefaultAsync(Object body, Option<bool?> bypassFilter = default, System.Threading.CancellationToken cancellationToken = default)
        {
            try
            {
                return await GenerateChatCompletionOpenaiChatCompletionsPostAsync(body, bypassFilter, cancellationToken).ConfigureAwait(false);
            }
            catch (Exception)
            {
                return null;
            }
        }

        /// <summary>
        /// Generate Chat Completion 
        /// </summary>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="body"></param>
        /// <param name="bypassFilter"> (optional)</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGenerateChatCompletionOpenaiChatCompletionsPostApiResponse"/>&gt;</returns>
        public async Task<IGenerateChatCompletionOpenaiChatCompletionsPostApiResponse> GenerateChatCompletionOpenaiChatCompletionsPostAsync(Object body, Option<bool?> bypassFilter = default, System.Threading.CancellationToken cancellationToken = default)
        {
            UriBuilder uriBuilderLocalVar = new UriBuilder();

            try
            {
                ValidateGenerateChatCompletionOpenaiChatCompletionsPost(body);

                FormatGenerateChatCompletionOpenaiChatCompletionsPost(ref body, ref bypassFilter);

                using (HttpRequestMessage httpRequestMessageLocalVar = new HttpRequestMessage())
                {
                    uriBuilderLocalVar.Host = HttpClient.BaseAddress!.Host;
                    uriBuilderLocalVar.Port = HttpClient.BaseAddress.Port;
                    uriBuilderLocalVar.Scheme = HttpClient.BaseAddress.Scheme;
                    uriBuilderLocalVar.Path = HttpClient.BaseAddress.AbsolutePath == "/"
                        ? "/openai/chat/completions"
                        : string.Concat(HttpClient.BaseAddress.AbsolutePath, "/openai/chat/completions");

                    System.Collections.Specialized.NameValueCollection parseQueryStringLocalVar = System.Web.HttpUtility.ParseQueryString(string.Empty);

                    if (bypassFilter.IsSet)
                        parseQueryStringLocalVar["bypass_filter"] = ClientUtils.ParameterToString(bypassFilter.Value);

                    uriBuilderLocalVar.Query = parseQueryStringLocalVar.ToString();

                    httpRequestMessageLocalVar.Content = (body as object) is System.IO.Stream stream
                        ? httpRequestMessageLocalVar.Content = new StreamContent(stream)
                        : httpRequestMessageLocalVar.Content = new StringContent(JsonSerializer.Serialize(body, _jsonSerializerOptions));

                    List<TokenBase> tokenBaseLocalVars = new List<TokenBase>();
                    httpRequestMessageLocalVar.RequestUri = uriBuilderLocalVar.Uri;

                    BearerToken bearerTokenLocalVar1 = (BearerToken) await BearerTokenProvider.GetAsync(cancellation: cancellationToken).ConfigureAwait(false);

                    tokenBaseLocalVars.Add(bearerTokenLocalVar1);

                    bearerTokenLocalVar1.UseInHeader(httpRequestMessageLocalVar, "");

                    string[] contentTypes = new string[] {
                        "application/json"
                    };

                    string? contentTypeLocalVar = ClientUtils.SelectHeaderContentType(contentTypes);

                    if (contentTypeLocalVar != null && httpRequestMessageLocalVar.Content != null)
                        httpRequestMessageLocalVar.Content.Headers.ContentType = new MediaTypeHeaderValue(contentTypeLocalVar);

                    string[] acceptLocalVars = new string[] {
                        "application/json"
                    };

                    string? acceptLocalVar = ClientUtils.SelectHeaderAccept(acceptLocalVars);

                    if (acceptLocalVar != null)
                        httpRequestMessageLocalVar.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(acceptLocalVar));

                    httpRequestMessageLocalVar.Method = HttpMethod.Post;

                    DateTime requestedAtLocalVar = DateTime.UtcNow;

                    using (HttpResponseMessage httpResponseMessageLocalVar = await HttpClient.SendAsync(httpRequestMessageLocalVar, cancellationToken).ConfigureAwait(false))
                    {
                        string responseContentLocalVar = await httpResponseMessageLocalVar.Content.ReadAsStringAsync(cancellationToken).ConfigureAwait(false);

                        ILogger<GenerateChatCompletionOpenaiChatCompletionsPostApiResponse> apiResponseLoggerLocalVar = LoggerFactory.CreateLogger<GenerateChatCompletionOpenaiChatCompletionsPostApiResponse>();

                        GenerateChatCompletionOpenaiChatCompletionsPostApiResponse apiResponseLocalVar = new(apiResponseLoggerLocalVar, httpRequestMessageLocalVar, httpResponseMessageLocalVar, responseContentLocalVar, "/openai/chat/completions", requestedAtLocalVar, _jsonSerializerOptions);

                        AfterGenerateChatCompletionOpenaiChatCompletionsPostDefaultImplementation(apiResponseLocalVar, body, bypassFilter);

                        Events.ExecuteOnGenerateChatCompletionOpenaiChatCompletionsPost(apiResponseLocalVar);

                        if (apiResponseLocalVar.StatusCode == (HttpStatusCode) 429)
                            foreach(TokenBase tokenBaseLocalVar in tokenBaseLocalVars)
                                tokenBaseLocalVar.BeginRateLimit();

                        return apiResponseLocalVar;
                    }
                }
            }
            catch(Exception e)
            {
                OnErrorGenerateChatCompletionOpenaiChatCompletionsPostDefaultImplementation(e, "/openai/chat/completions", uriBuilderLocalVar.Path, body, bypassFilter);
                Events.ExecuteOnErrorGenerateChatCompletionOpenaiChatCompletionsPost(e);
                throw;
            }
        }

        /// <summary>
        /// The <see cref="GenerateChatCompletionOpenaiChatCompletionsPostApiResponse"/>
        /// </summary>
        public partial class GenerateChatCompletionOpenaiChatCompletionsPostApiResponse : Org.OpenAPITools.Client.ApiResponse, IGenerateChatCompletionOpenaiChatCompletionsPostApiResponse
        {
            /// <summary>
            /// The logger
            /// </summary>
            public ILogger<GenerateChatCompletionOpenaiChatCompletionsPostApiResponse> Logger { get; }

            /// <summary>
            /// The <see cref="GenerateChatCompletionOpenaiChatCompletionsPostApiResponse"/>
            /// </summary>
            /// <param name="logger"></param>
            /// <param name="httpRequestMessage"></param>
            /// <param name="httpResponseMessage"></param>
            /// <param name="rawContent"></param>
            /// <param name="path"></param>
            /// <param name="requestedAt"></param>
            /// <param name="jsonSerializerOptions"></param>
            public GenerateChatCompletionOpenaiChatCompletionsPostApiResponse(ILogger<GenerateChatCompletionOpenaiChatCompletionsPostApiResponse> logger, System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage, string rawContent, string path, DateTime requestedAt, System.Text.Json.JsonSerializerOptions jsonSerializerOptions) : base(httpRequestMessage, httpResponseMessage, rawContent, path, requestedAt, jsonSerializerOptions)
            {
                Logger = logger;
                OnCreated(httpRequestMessage, httpResponseMessage);
            }

            partial void OnCreated(global::System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage);

            /// <summary>
            /// Returns true if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public bool IsOk => 200 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public Object? Ok()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsOk
                    ? System.Text.Json.JsonSerializer.Deserialize<Object>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 200 Ok and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryOk([NotNullWhen(true)]out Object? result)
            {
                result = null;

                try
                {
                    result = Ok();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)200);
                }

                return result != null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public bool IsUnprocessableContent => 422 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public Org.OpenAPITools.Model.HTTPValidationError? UnprocessableContent()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsUnprocessableContent
                    ? System.Text.Json.JsonSerializer.Deserialize<Org.OpenAPITools.Model.HTTPValidationError>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryUnprocessableContent([NotNullWhen(true)]out Org.OpenAPITools.Model.HTTPValidationError? result)
            {
                result = null;

                try
                {
                    result = UnprocessableContent();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)422);
                }

                return result != null;
            }

            private void OnDeserializationErrorDefaultImplementation(Exception exception, HttpStatusCode httpStatusCode)
            {
                bool suppressDefaultLog = false;
                OnDeserializationError(ref suppressDefaultLog, exception, httpStatusCode);
                if (!suppressDefaultLog)
                    Logger.LogError(exception, "An error occurred while deserializing the {code} response.", httpStatusCode);
            }

            partial void OnDeserializationError(ref bool suppressDefaultLog, Exception exception, HttpStatusCode httpStatusCode);
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="apiResponseLocalVar"></param>
        private void AfterGetConfigOpenaiConfigGetDefaultImplementation(IGetConfigOpenaiConfigGetApiResponse apiResponseLocalVar)
        {
            bool suppressDefaultLog = false;
            AfterGetConfigOpenaiConfigGet(ref suppressDefaultLog, apiResponseLocalVar);
            if (!suppressDefaultLog)
                Logger.LogInformation("{0,-9} | {1} | {3}", (apiResponseLocalVar.DownloadedAt - apiResponseLocalVar.RequestedAt).TotalSeconds, apiResponseLocalVar.StatusCode, apiResponseLocalVar.Path);
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="suppressDefaultLog"></param>
        /// <param name="apiResponseLocalVar"></param>
        partial void AfterGetConfigOpenaiConfigGet(ref bool suppressDefaultLog, IGetConfigOpenaiConfigGetApiResponse apiResponseLocalVar);

        /// <summary>
        /// Logs exceptions that occur while retrieving the server response
        /// </summary>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        private void OnErrorGetConfigOpenaiConfigGetDefaultImplementation(Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar)
        {
            bool suppressDefaultLogLocalVar = false;
            OnErrorGetConfigOpenaiConfigGet(ref suppressDefaultLogLocalVar, exceptionLocalVar, pathFormatLocalVar, pathLocalVar);
            if (!suppressDefaultLogLocalVar)
                Logger.LogError(exceptionLocalVar, "An error occurred while sending the request to the server.");
        }

        /// <summary>
        /// A partial method that gives developers a way to provide customized exception handling
        /// </summary>
        /// <param name="suppressDefaultLogLocalVar"></param>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        partial void OnErrorGetConfigOpenaiConfigGet(ref bool suppressDefaultLogLocalVar, Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar);

        /// <summary>
        /// Get Config 
        /// </summary>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGetConfigOpenaiConfigGetApiResponse"/>&gt;</returns>
        public async Task<IGetConfigOpenaiConfigGetApiResponse?> GetConfigOpenaiConfigGetOrDefaultAsync(System.Threading.CancellationToken cancellationToken = default)
        {
            try
            {
                return await GetConfigOpenaiConfigGetAsync(cancellationToken).ConfigureAwait(false);
            }
            catch (Exception)
            {
                return null;
            }
        }

        /// <summary>
        /// Get Config 
        /// </summary>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGetConfigOpenaiConfigGetApiResponse"/>&gt;</returns>
        public async Task<IGetConfigOpenaiConfigGetApiResponse> GetConfigOpenaiConfigGetAsync(System.Threading.CancellationToken cancellationToken = default)
        {
            UriBuilder uriBuilderLocalVar = new UriBuilder();

            try
            {
                using (HttpRequestMessage httpRequestMessageLocalVar = new HttpRequestMessage())
                {
                    uriBuilderLocalVar.Host = HttpClient.BaseAddress!.Host;
                    uriBuilderLocalVar.Port = HttpClient.BaseAddress.Port;
                    uriBuilderLocalVar.Scheme = HttpClient.BaseAddress.Scheme;
                    uriBuilderLocalVar.Path = HttpClient.BaseAddress.AbsolutePath == "/"
                        ? "/openai/config"
                        : string.Concat(HttpClient.BaseAddress.AbsolutePath, "/openai/config");

                    List<TokenBase> tokenBaseLocalVars = new List<TokenBase>();
                    httpRequestMessageLocalVar.RequestUri = uriBuilderLocalVar.Uri;

                    BearerToken bearerTokenLocalVar1 = (BearerToken) await BearerTokenProvider.GetAsync(cancellation: cancellationToken).ConfigureAwait(false);

                    tokenBaseLocalVars.Add(bearerTokenLocalVar1);

                    bearerTokenLocalVar1.UseInHeader(httpRequestMessageLocalVar, "");

                    string[] acceptLocalVars = new string[] {
                        "application/json"
                    };

                    string? acceptLocalVar = ClientUtils.SelectHeaderAccept(acceptLocalVars);

                    if (acceptLocalVar != null)
                        httpRequestMessageLocalVar.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(acceptLocalVar));

                    httpRequestMessageLocalVar.Method = HttpMethod.Get;

                    DateTime requestedAtLocalVar = DateTime.UtcNow;

                    using (HttpResponseMessage httpResponseMessageLocalVar = await HttpClient.SendAsync(httpRequestMessageLocalVar, cancellationToken).ConfigureAwait(false))
                    {
                        string responseContentLocalVar = await httpResponseMessageLocalVar.Content.ReadAsStringAsync(cancellationToken).ConfigureAwait(false);

                        ILogger<GetConfigOpenaiConfigGetApiResponse> apiResponseLoggerLocalVar = LoggerFactory.CreateLogger<GetConfigOpenaiConfigGetApiResponse>();

                        GetConfigOpenaiConfigGetApiResponse apiResponseLocalVar = new(apiResponseLoggerLocalVar, httpRequestMessageLocalVar, httpResponseMessageLocalVar, responseContentLocalVar, "/openai/config", requestedAtLocalVar, _jsonSerializerOptions);

                        AfterGetConfigOpenaiConfigGetDefaultImplementation(apiResponseLocalVar);

                        Events.ExecuteOnGetConfigOpenaiConfigGet(apiResponseLocalVar);

                        if (apiResponseLocalVar.StatusCode == (HttpStatusCode) 429)
                            foreach(TokenBase tokenBaseLocalVar in tokenBaseLocalVars)
                                tokenBaseLocalVar.BeginRateLimit();

                        return apiResponseLocalVar;
                    }
                }
            }
            catch(Exception e)
            {
                OnErrorGetConfigOpenaiConfigGetDefaultImplementation(e, "/openai/config", uriBuilderLocalVar.Path);
                Events.ExecuteOnErrorGetConfigOpenaiConfigGet(e);
                throw;
            }
        }

        /// <summary>
        /// The <see cref="GetConfigOpenaiConfigGetApiResponse"/>
        /// </summary>
        public partial class GetConfigOpenaiConfigGetApiResponse : Org.OpenAPITools.Client.ApiResponse, IGetConfigOpenaiConfigGetApiResponse
        {
            /// <summary>
            /// The logger
            /// </summary>
            public ILogger<GetConfigOpenaiConfigGetApiResponse> Logger { get; }

            /// <summary>
            /// The <see cref="GetConfigOpenaiConfigGetApiResponse"/>
            /// </summary>
            /// <param name="logger"></param>
            /// <param name="httpRequestMessage"></param>
            /// <param name="httpResponseMessage"></param>
            /// <param name="rawContent"></param>
            /// <param name="path"></param>
            /// <param name="requestedAt"></param>
            /// <param name="jsonSerializerOptions"></param>
            public GetConfigOpenaiConfigGetApiResponse(ILogger<GetConfigOpenaiConfigGetApiResponse> logger, System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage, string rawContent, string path, DateTime requestedAt, System.Text.Json.JsonSerializerOptions jsonSerializerOptions) : base(httpRequestMessage, httpResponseMessage, rawContent, path, requestedAt, jsonSerializerOptions)
            {
                Logger = logger;
                OnCreated(httpRequestMessage, httpResponseMessage);
            }

            partial void OnCreated(global::System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage);

            /// <summary>
            /// Returns true if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public bool IsOk => 200 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public Object? Ok()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsOk
                    ? System.Text.Json.JsonSerializer.Deserialize<Object>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 200 Ok and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryOk([NotNullWhen(true)]out Object? result)
            {
                result = null;

                try
                {
                    result = Ok();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)200);
                }

                return result != null;
            }

            private void OnDeserializationErrorDefaultImplementation(Exception exception, HttpStatusCode httpStatusCode)
            {
                bool suppressDefaultLog = false;
                OnDeserializationError(ref suppressDefaultLog, exception, httpStatusCode);
                if (!suppressDefaultLog)
                    Logger.LogError(exception, "An error occurred while deserializing the {code} response.", httpStatusCode);
            }

            partial void OnDeserializationError(ref bool suppressDefaultLog, Exception exception, HttpStatusCode httpStatusCode);
        }

        partial void FormatGetModelsOpenaiModelsGet(ref Option<int?> urlIdx);

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="urlIdx"></param>
        private void AfterGetModelsOpenaiModelsGetDefaultImplementation(IGetModelsOpenaiModelsGetApiResponse apiResponseLocalVar, Option<int?> urlIdx)
        {
            bool suppressDefaultLog = false;
            AfterGetModelsOpenaiModelsGet(ref suppressDefaultLog, apiResponseLocalVar, urlIdx);
            if (!suppressDefaultLog)
                Logger.LogInformation("{0,-9} | {1} | {3}", (apiResponseLocalVar.DownloadedAt - apiResponseLocalVar.RequestedAt).TotalSeconds, apiResponseLocalVar.StatusCode, apiResponseLocalVar.Path);
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="suppressDefaultLog"></param>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="urlIdx"></param>
        partial void AfterGetModelsOpenaiModelsGet(ref bool suppressDefaultLog, IGetModelsOpenaiModelsGetApiResponse apiResponseLocalVar, Option<int?> urlIdx);

        /// <summary>
        /// Logs exceptions that occur while retrieving the server response
        /// </summary>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="urlIdx"></param>
        private void OnErrorGetModelsOpenaiModelsGetDefaultImplementation(Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, Option<int?> urlIdx)
        {
            bool suppressDefaultLogLocalVar = false;
            OnErrorGetModelsOpenaiModelsGet(ref suppressDefaultLogLocalVar, exceptionLocalVar, pathFormatLocalVar, pathLocalVar, urlIdx);
            if (!suppressDefaultLogLocalVar)
                Logger.LogError(exceptionLocalVar, "An error occurred while sending the request to the server.");
        }

        /// <summary>
        /// A partial method that gives developers a way to provide customized exception handling
        /// </summary>
        /// <param name="suppressDefaultLogLocalVar"></param>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="urlIdx"></param>
        partial void OnErrorGetModelsOpenaiModelsGet(ref bool suppressDefaultLogLocalVar, Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, Option<int?> urlIdx);

        /// <summary>
        /// Get Models 
        /// </summary>
        /// <param name="urlIdx"> (optional)</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGetModelsOpenaiModelsGetApiResponse"/>&gt;</returns>
        public async Task<IGetModelsOpenaiModelsGetApiResponse?> GetModelsOpenaiModelsGetOrDefaultAsync(Option<int?> urlIdx = default, System.Threading.CancellationToken cancellationToken = default)
        {
            try
            {
                return await GetModelsOpenaiModelsGetAsync(urlIdx, cancellationToken).ConfigureAwait(false);
            }
            catch (Exception)
            {
                return null;
            }
        }

        /// <summary>
        /// Get Models 
        /// </summary>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="urlIdx"> (optional)</param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGetModelsOpenaiModelsGetApiResponse"/>&gt;</returns>
        public async Task<IGetModelsOpenaiModelsGetApiResponse> GetModelsOpenaiModelsGetAsync(Option<int?> urlIdx = default, System.Threading.CancellationToken cancellationToken = default)
        {
            UriBuilder uriBuilderLocalVar = new UriBuilder();

            try
            {
                FormatGetModelsOpenaiModelsGet(ref urlIdx);

                using (HttpRequestMessage httpRequestMessageLocalVar = new HttpRequestMessage())
                {
                    uriBuilderLocalVar.Host = HttpClient.BaseAddress!.Host;
                    uriBuilderLocalVar.Port = HttpClient.BaseAddress.Port;
                    uriBuilderLocalVar.Scheme = HttpClient.BaseAddress.Scheme;
                    uriBuilderLocalVar.Path = HttpClient.BaseAddress.AbsolutePath == "/"
                        ? "/openai/models"
                        : string.Concat(HttpClient.BaseAddress.AbsolutePath, "/openai/models");

                    System.Collections.Specialized.NameValueCollection parseQueryStringLocalVar = System.Web.HttpUtility.ParseQueryString(string.Empty);

                    if (urlIdx.IsSet)
                        parseQueryStringLocalVar["url_idx"] = ClientUtils.ParameterToString(urlIdx.Value);

                    uriBuilderLocalVar.Query = parseQueryStringLocalVar.ToString();

                    List<TokenBase> tokenBaseLocalVars = new List<TokenBase>();
                    httpRequestMessageLocalVar.RequestUri = uriBuilderLocalVar.Uri;

                    BearerToken bearerTokenLocalVar1 = (BearerToken) await BearerTokenProvider.GetAsync(cancellation: cancellationToken).ConfigureAwait(false);

                    tokenBaseLocalVars.Add(bearerTokenLocalVar1);

                    bearerTokenLocalVar1.UseInHeader(httpRequestMessageLocalVar, "");

                    string[] acceptLocalVars = new string[] {
                        "application/json"
                    };

                    string? acceptLocalVar = ClientUtils.SelectHeaderAccept(acceptLocalVars);

                    if (acceptLocalVar != null)
                        httpRequestMessageLocalVar.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(acceptLocalVar));

                    httpRequestMessageLocalVar.Method = HttpMethod.Get;

                    DateTime requestedAtLocalVar = DateTime.UtcNow;

                    using (HttpResponseMessage httpResponseMessageLocalVar = await HttpClient.SendAsync(httpRequestMessageLocalVar, cancellationToken).ConfigureAwait(false))
                    {
                        string responseContentLocalVar = await httpResponseMessageLocalVar.Content.ReadAsStringAsync(cancellationToken).ConfigureAwait(false);

                        ILogger<GetModelsOpenaiModelsGetApiResponse> apiResponseLoggerLocalVar = LoggerFactory.CreateLogger<GetModelsOpenaiModelsGetApiResponse>();

                        GetModelsOpenaiModelsGetApiResponse apiResponseLocalVar = new(apiResponseLoggerLocalVar, httpRequestMessageLocalVar, httpResponseMessageLocalVar, responseContentLocalVar, "/openai/models", requestedAtLocalVar, _jsonSerializerOptions);

                        AfterGetModelsOpenaiModelsGetDefaultImplementation(apiResponseLocalVar, urlIdx);

                        Events.ExecuteOnGetModelsOpenaiModelsGet(apiResponseLocalVar);

                        if (apiResponseLocalVar.StatusCode == (HttpStatusCode) 429)
                            foreach(TokenBase tokenBaseLocalVar in tokenBaseLocalVars)
                                tokenBaseLocalVar.BeginRateLimit();

                        return apiResponseLocalVar;
                    }
                }
            }
            catch(Exception e)
            {
                OnErrorGetModelsOpenaiModelsGetDefaultImplementation(e, "/openai/models", uriBuilderLocalVar.Path, urlIdx);
                Events.ExecuteOnErrorGetModelsOpenaiModelsGet(e);
                throw;
            }
        }

        /// <summary>
        /// The <see cref="GetModelsOpenaiModelsGetApiResponse"/>
        /// </summary>
        public partial class GetModelsOpenaiModelsGetApiResponse : Org.OpenAPITools.Client.ApiResponse, IGetModelsOpenaiModelsGetApiResponse
        {
            /// <summary>
            /// The logger
            /// </summary>
            public ILogger<GetModelsOpenaiModelsGetApiResponse> Logger { get; }

            /// <summary>
            /// The <see cref="GetModelsOpenaiModelsGetApiResponse"/>
            /// </summary>
            /// <param name="logger"></param>
            /// <param name="httpRequestMessage"></param>
            /// <param name="httpResponseMessage"></param>
            /// <param name="rawContent"></param>
            /// <param name="path"></param>
            /// <param name="requestedAt"></param>
            /// <param name="jsonSerializerOptions"></param>
            public GetModelsOpenaiModelsGetApiResponse(ILogger<GetModelsOpenaiModelsGetApiResponse> logger, System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage, string rawContent, string path, DateTime requestedAt, System.Text.Json.JsonSerializerOptions jsonSerializerOptions) : base(httpRequestMessage, httpResponseMessage, rawContent, path, requestedAt, jsonSerializerOptions)
            {
                Logger = logger;
                OnCreated(httpRequestMessage, httpResponseMessage);
            }

            partial void OnCreated(global::System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage);

            /// <summary>
            /// Returns true if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public bool IsOk => 200 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public Object? Ok()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsOk
                    ? System.Text.Json.JsonSerializer.Deserialize<Object>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 200 Ok and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryOk([NotNullWhen(true)]out Object? result)
            {
                result = null;

                try
                {
                    result = Ok();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)200);
                }

                return result != null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public bool IsUnprocessableContent => 422 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public Org.OpenAPITools.Model.HTTPValidationError? UnprocessableContent()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsUnprocessableContent
                    ? System.Text.Json.JsonSerializer.Deserialize<Org.OpenAPITools.Model.HTTPValidationError>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryUnprocessableContent([NotNullWhen(true)]out Org.OpenAPITools.Model.HTTPValidationError? result)
            {
                result = null;

                try
                {
                    result = UnprocessableContent();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)422);
                }

                return result != null;
            }

            private void OnDeserializationErrorDefaultImplementation(Exception exception, HttpStatusCode httpStatusCode)
            {
                bool suppressDefaultLog = false;
                OnDeserializationError(ref suppressDefaultLog, exception, httpStatusCode);
                if (!suppressDefaultLog)
                    Logger.LogError(exception, "An error occurred while deserializing the {code} response.", httpStatusCode);
            }

            partial void OnDeserializationError(ref bool suppressDefaultLog, Exception exception, HttpStatusCode httpStatusCode);
        }

        partial void FormatGetModelsOpenaiModelsUrlIdxGet(ref int? urlIdx);

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="urlIdx"></param>
        private void AfterGetModelsOpenaiModelsUrlIdxGetDefaultImplementation(IGetModelsOpenaiModelsUrlIdxGetApiResponse apiResponseLocalVar, int? urlIdx)
        {
            bool suppressDefaultLog = false;
            AfterGetModelsOpenaiModelsUrlIdxGet(ref suppressDefaultLog, apiResponseLocalVar, urlIdx);
            if (!suppressDefaultLog)
                Logger.LogInformation("{0,-9} | {1} | {3}", (apiResponseLocalVar.DownloadedAt - apiResponseLocalVar.RequestedAt).TotalSeconds, apiResponseLocalVar.StatusCode, apiResponseLocalVar.Path);
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="suppressDefaultLog"></param>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="urlIdx"></param>
        partial void AfterGetModelsOpenaiModelsUrlIdxGet(ref bool suppressDefaultLog, IGetModelsOpenaiModelsUrlIdxGetApiResponse apiResponseLocalVar, int? urlIdx);

        /// <summary>
        /// Logs exceptions that occur while retrieving the server response
        /// </summary>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="urlIdx"></param>
        private void OnErrorGetModelsOpenaiModelsUrlIdxGetDefaultImplementation(Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, int? urlIdx)
        {
            bool suppressDefaultLogLocalVar = false;
            OnErrorGetModelsOpenaiModelsUrlIdxGet(ref suppressDefaultLogLocalVar, exceptionLocalVar, pathFormatLocalVar, pathLocalVar, urlIdx);
            if (!suppressDefaultLogLocalVar)
                Logger.LogError(exceptionLocalVar, "An error occurred while sending the request to the server.");
        }

        /// <summary>
        /// A partial method that gives developers a way to provide customized exception handling
        /// </summary>
        /// <param name="suppressDefaultLogLocalVar"></param>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="urlIdx"></param>
        partial void OnErrorGetModelsOpenaiModelsUrlIdxGet(ref bool suppressDefaultLogLocalVar, Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, int? urlIdx);

        /// <summary>
        /// Get Models 
        /// </summary>
        /// <param name="urlIdx"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGetModelsOpenaiModelsUrlIdxGetApiResponse"/>&gt;</returns>
        public async Task<IGetModelsOpenaiModelsUrlIdxGetApiResponse?> GetModelsOpenaiModelsUrlIdxGetOrDefaultAsync(int? urlIdx = default, System.Threading.CancellationToken cancellationToken = default)
        {
            try
            {
                return await GetModelsOpenaiModelsUrlIdxGetAsync(urlIdx, cancellationToken).ConfigureAwait(false);
            }
            catch (Exception)
            {
                return null;
            }
        }

        /// <summary>
        /// Get Models 
        /// </summary>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="urlIdx"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IGetModelsOpenaiModelsUrlIdxGetApiResponse"/>&gt;</returns>
        public async Task<IGetModelsOpenaiModelsUrlIdxGetApiResponse> GetModelsOpenaiModelsUrlIdxGetAsync(int? urlIdx = default, System.Threading.CancellationToken cancellationToken = default)
        {
            UriBuilder uriBuilderLocalVar = new UriBuilder();

            try
            {
                FormatGetModelsOpenaiModelsUrlIdxGet(ref urlIdx);

                using (HttpRequestMessage httpRequestMessageLocalVar = new HttpRequestMessage())
                {
                    uriBuilderLocalVar.Host = HttpClient.BaseAddress!.Host;
                    uriBuilderLocalVar.Port = HttpClient.BaseAddress.Port;
                    uriBuilderLocalVar.Scheme = HttpClient.BaseAddress.Scheme;
                    uriBuilderLocalVar.Path = HttpClient.BaseAddress.AbsolutePath == "/"
                        ? "/openai/models/{url_idx}"
                        : string.Concat(HttpClient.BaseAddress.AbsolutePath, "/openai/models/{url_idx}");
                    uriBuilderLocalVar.Path = uriBuilderLocalVar.Path.Replace("%7Burl_idx%7D", Uri.EscapeDataString(urlIdx.ToString()));

                    List<TokenBase> tokenBaseLocalVars = new List<TokenBase>();
                    httpRequestMessageLocalVar.RequestUri = uriBuilderLocalVar.Uri;

                    BearerToken bearerTokenLocalVar1 = (BearerToken) await BearerTokenProvider.GetAsync(cancellation: cancellationToken).ConfigureAwait(false);

                    tokenBaseLocalVars.Add(bearerTokenLocalVar1);

                    bearerTokenLocalVar1.UseInHeader(httpRequestMessageLocalVar, "");

                    string[] acceptLocalVars = new string[] {
                        "application/json"
                    };

                    string? acceptLocalVar = ClientUtils.SelectHeaderAccept(acceptLocalVars);

                    if (acceptLocalVar != null)
                        httpRequestMessageLocalVar.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(acceptLocalVar));

                    httpRequestMessageLocalVar.Method = HttpMethod.Get;

                    DateTime requestedAtLocalVar = DateTime.UtcNow;

                    using (HttpResponseMessage httpResponseMessageLocalVar = await HttpClient.SendAsync(httpRequestMessageLocalVar, cancellationToken).ConfigureAwait(false))
                    {
                        string responseContentLocalVar = await httpResponseMessageLocalVar.Content.ReadAsStringAsync(cancellationToken).ConfigureAwait(false);

                        ILogger<GetModelsOpenaiModelsUrlIdxGetApiResponse> apiResponseLoggerLocalVar = LoggerFactory.CreateLogger<GetModelsOpenaiModelsUrlIdxGetApiResponse>();

                        GetModelsOpenaiModelsUrlIdxGetApiResponse apiResponseLocalVar = new(apiResponseLoggerLocalVar, httpRequestMessageLocalVar, httpResponseMessageLocalVar, responseContentLocalVar, "/openai/models/{url_idx}", requestedAtLocalVar, _jsonSerializerOptions);

                        AfterGetModelsOpenaiModelsUrlIdxGetDefaultImplementation(apiResponseLocalVar, urlIdx);

                        Events.ExecuteOnGetModelsOpenaiModelsUrlIdxGet(apiResponseLocalVar);

                        if (apiResponseLocalVar.StatusCode == (HttpStatusCode) 429)
                            foreach(TokenBase tokenBaseLocalVar in tokenBaseLocalVars)
                                tokenBaseLocalVar.BeginRateLimit();

                        return apiResponseLocalVar;
                    }
                }
            }
            catch(Exception e)
            {
                OnErrorGetModelsOpenaiModelsUrlIdxGetDefaultImplementation(e, "/openai/models/{url_idx}", uriBuilderLocalVar.Path, urlIdx);
                Events.ExecuteOnErrorGetModelsOpenaiModelsUrlIdxGet(e);
                throw;
            }
        }

        /// <summary>
        /// The <see cref="GetModelsOpenaiModelsUrlIdxGetApiResponse"/>
        /// </summary>
        public partial class GetModelsOpenaiModelsUrlIdxGetApiResponse : Org.OpenAPITools.Client.ApiResponse, IGetModelsOpenaiModelsUrlIdxGetApiResponse
        {
            /// <summary>
            /// The logger
            /// </summary>
            public ILogger<GetModelsOpenaiModelsUrlIdxGetApiResponse> Logger { get; }

            /// <summary>
            /// The <see cref="GetModelsOpenaiModelsUrlIdxGetApiResponse"/>
            /// </summary>
            /// <param name="logger"></param>
            /// <param name="httpRequestMessage"></param>
            /// <param name="httpResponseMessage"></param>
            /// <param name="rawContent"></param>
            /// <param name="path"></param>
            /// <param name="requestedAt"></param>
            /// <param name="jsonSerializerOptions"></param>
            public GetModelsOpenaiModelsUrlIdxGetApiResponse(ILogger<GetModelsOpenaiModelsUrlIdxGetApiResponse> logger, System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage, string rawContent, string path, DateTime requestedAt, System.Text.Json.JsonSerializerOptions jsonSerializerOptions) : base(httpRequestMessage, httpResponseMessage, rawContent, path, requestedAt, jsonSerializerOptions)
            {
                Logger = logger;
                OnCreated(httpRequestMessage, httpResponseMessage);
            }

            partial void OnCreated(global::System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage);

            /// <summary>
            /// Returns true if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public bool IsOk => 200 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public Object? Ok()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsOk
                    ? System.Text.Json.JsonSerializer.Deserialize<Object>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 200 Ok and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryOk([NotNullWhen(true)]out Object? result)
            {
                result = null;

                try
                {
                    result = Ok();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)200);
                }

                return result != null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public bool IsUnprocessableContent => 422 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public Org.OpenAPITools.Model.HTTPValidationError? UnprocessableContent()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsUnprocessableContent
                    ? System.Text.Json.JsonSerializer.Deserialize<Org.OpenAPITools.Model.HTTPValidationError>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryUnprocessableContent([NotNullWhen(true)]out Org.OpenAPITools.Model.HTTPValidationError? result)
            {
                result = null;

                try
                {
                    result = UnprocessableContent();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)422);
                }

                return result != null;
            }

            private void OnDeserializationErrorDefaultImplementation(Exception exception, HttpStatusCode httpStatusCode)
            {
                bool suppressDefaultLog = false;
                OnDeserializationError(ref suppressDefaultLog, exception, httpStatusCode);
                if (!suppressDefaultLog)
                    Logger.LogError(exception, "An error occurred while deserializing the {code} response.", httpStatusCode);
            }

            partial void OnDeserializationError(ref bool suppressDefaultLog, Exception exception, HttpStatusCode httpStatusCode);
        }

        partial void FormatProxyOpenaiPathDelete(ref string path);

        /// <summary>
        /// Validates the request parameters
        /// </summary>
        /// <param name="path"></param>
        /// <returns></returns>
        private void ValidateProxyOpenaiPathDelete(string path)
        {
            if (path == null)
                throw new ArgumentNullException(nameof(path));
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="path"></param>
        private void AfterProxyOpenaiPathDeleteDefaultImplementation(IProxyOpenaiPathDeleteApiResponse apiResponseLocalVar, string path)
        {
            bool suppressDefaultLog = false;
            AfterProxyOpenaiPathDelete(ref suppressDefaultLog, apiResponseLocalVar, path);
            if (!suppressDefaultLog)
                Logger.LogInformation("{0,-9} | {1} | {3}", (apiResponseLocalVar.DownloadedAt - apiResponseLocalVar.RequestedAt).TotalSeconds, apiResponseLocalVar.StatusCode, apiResponseLocalVar.Path);
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="suppressDefaultLog"></param>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="path"></param>
        partial void AfterProxyOpenaiPathDelete(ref bool suppressDefaultLog, IProxyOpenaiPathDeleteApiResponse apiResponseLocalVar, string path);

        /// <summary>
        /// Logs exceptions that occur while retrieving the server response
        /// </summary>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="path"></param>
        private void OnErrorProxyOpenaiPathDeleteDefaultImplementation(Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, string path)
        {
            bool suppressDefaultLogLocalVar = false;
            OnErrorProxyOpenaiPathDelete(ref suppressDefaultLogLocalVar, exceptionLocalVar, pathFormatLocalVar, pathLocalVar, path);
            if (!suppressDefaultLogLocalVar)
                Logger.LogError(exceptionLocalVar, "An error occurred while sending the request to the server.");
        }

        /// <summary>
        /// A partial method that gives developers a way to provide customized exception handling
        /// </summary>
        /// <param name="suppressDefaultLogLocalVar"></param>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="path"></param>
        partial void OnErrorProxyOpenaiPathDelete(ref bool suppressDefaultLogLocalVar, Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, string path);

        /// <summary>
        /// Proxy Deprecated: proxy all requests to OpenAI API
        /// </summary>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDeleteApiResponse"/>&gt;</returns>
        public async Task<IProxyOpenaiPathDeleteApiResponse?> ProxyOpenaiPathDeleteOrDefaultAsync(string path, System.Threading.CancellationToken cancellationToken = default)
        {
            try
            {
                return await ProxyOpenaiPathDeleteAsync(path, cancellationToken).ConfigureAwait(false);
            }
            catch (Exception)
            {
                return null;
            }
        }

        /// <summary>
        /// Proxy Deprecated: proxy all requests to OpenAI API
        /// </summary>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDeleteApiResponse"/>&gt;</returns>
        public async Task<IProxyOpenaiPathDeleteApiResponse> ProxyOpenaiPathDeleteAsync(string path, System.Threading.CancellationToken cancellationToken = default)
        {
            UriBuilder uriBuilderLocalVar = new UriBuilder();

            try
            {
                ValidateProxyOpenaiPathDelete(path);

                FormatProxyOpenaiPathDelete(ref path);

                using (HttpRequestMessage httpRequestMessageLocalVar = new HttpRequestMessage())
                {
                    uriBuilderLocalVar.Host = HttpClient.BaseAddress!.Host;
                    uriBuilderLocalVar.Port = HttpClient.BaseAddress.Port;
                    uriBuilderLocalVar.Scheme = HttpClient.BaseAddress.Scheme;
                    uriBuilderLocalVar.Path = HttpClient.BaseAddress.AbsolutePath == "/"
                        ? "/openai/{path}"
                        : string.Concat(HttpClient.BaseAddress.AbsolutePath, "/openai/{path}");
                    uriBuilderLocalVar.Path = uriBuilderLocalVar.Path.Replace("%7Bpath%7D", Uri.EscapeDataString(path.ToString()));

                    List<TokenBase> tokenBaseLocalVars = new List<TokenBase>();
                    httpRequestMessageLocalVar.RequestUri = uriBuilderLocalVar.Uri;

                    BearerToken bearerTokenLocalVar1 = (BearerToken) await BearerTokenProvider.GetAsync(cancellation: cancellationToken).ConfigureAwait(false);

                    tokenBaseLocalVars.Add(bearerTokenLocalVar1);

                    bearerTokenLocalVar1.UseInHeader(httpRequestMessageLocalVar, "");

                    string[] acceptLocalVars = new string[] {
                        "application/json"
                    };

                    string? acceptLocalVar = ClientUtils.SelectHeaderAccept(acceptLocalVars);

                    if (acceptLocalVar != null)
                        httpRequestMessageLocalVar.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(acceptLocalVar));

                    httpRequestMessageLocalVar.Method = HttpMethod.Get;

                    DateTime requestedAtLocalVar = DateTime.UtcNow;

                    using (HttpResponseMessage httpResponseMessageLocalVar = await HttpClient.SendAsync(httpRequestMessageLocalVar, cancellationToken).ConfigureAwait(false))
                    {
                        string responseContentLocalVar = await httpResponseMessageLocalVar.Content.ReadAsStringAsync(cancellationToken).ConfigureAwait(false);

                        ILogger<ProxyOpenaiPathDeleteApiResponse> apiResponseLoggerLocalVar = LoggerFactory.CreateLogger<ProxyOpenaiPathDeleteApiResponse>();

                        ProxyOpenaiPathDeleteApiResponse apiResponseLocalVar = new(apiResponseLoggerLocalVar, httpRequestMessageLocalVar, httpResponseMessageLocalVar, responseContentLocalVar, "/openai/{path}", requestedAtLocalVar, _jsonSerializerOptions);

                        AfterProxyOpenaiPathDeleteDefaultImplementation(apiResponseLocalVar, path);

                        Events.ExecuteOnProxyOpenaiPathDelete(apiResponseLocalVar);

                        if (apiResponseLocalVar.StatusCode == (HttpStatusCode) 429)
                            foreach(TokenBase tokenBaseLocalVar in tokenBaseLocalVars)
                                tokenBaseLocalVar.BeginRateLimit();

                        return apiResponseLocalVar;
                    }
                }
            }
            catch(Exception e)
            {
                OnErrorProxyOpenaiPathDeleteDefaultImplementation(e, "/openai/{path}", uriBuilderLocalVar.Path, path);
                Events.ExecuteOnErrorProxyOpenaiPathDelete(e);
                throw;
            }
        }

        /// <summary>
        /// The <see cref="ProxyOpenaiPathDeleteApiResponse"/>
        /// </summary>
        public partial class ProxyOpenaiPathDeleteApiResponse : Org.OpenAPITools.Client.ApiResponse, IProxyOpenaiPathDeleteApiResponse
        {
            /// <summary>
            /// The logger
            /// </summary>
            public ILogger<ProxyOpenaiPathDeleteApiResponse> Logger { get; }

            /// <summary>
            /// The <see cref="ProxyOpenaiPathDeleteApiResponse"/>
            /// </summary>
            /// <param name="logger"></param>
            /// <param name="httpRequestMessage"></param>
            /// <param name="httpResponseMessage"></param>
            /// <param name="rawContent"></param>
            /// <param name="path"></param>
            /// <param name="requestedAt"></param>
            /// <param name="jsonSerializerOptions"></param>
            public ProxyOpenaiPathDeleteApiResponse(ILogger<ProxyOpenaiPathDeleteApiResponse> logger, System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage, string rawContent, string path, DateTime requestedAt, System.Text.Json.JsonSerializerOptions jsonSerializerOptions) : base(httpRequestMessage, httpResponseMessage, rawContent, path, requestedAt, jsonSerializerOptions)
            {
                Logger = logger;
                OnCreated(httpRequestMessage, httpResponseMessage);
            }

            partial void OnCreated(global::System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage);

            /// <summary>
            /// Returns true if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public bool IsOk => 200 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public Object? Ok()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsOk
                    ? System.Text.Json.JsonSerializer.Deserialize<Object>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 200 Ok and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryOk([NotNullWhen(true)]out Object? result)
            {
                result = null;

                try
                {
                    result = Ok();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)200);
                }

                return result != null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public bool IsUnprocessableContent => 422 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public Org.OpenAPITools.Model.HTTPValidationError? UnprocessableContent()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsUnprocessableContent
                    ? System.Text.Json.JsonSerializer.Deserialize<Org.OpenAPITools.Model.HTTPValidationError>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryUnprocessableContent([NotNullWhen(true)]out Org.OpenAPITools.Model.HTTPValidationError? result)
            {
                result = null;

                try
                {
                    result = UnprocessableContent();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)422);
                }

                return result != null;
            }

            private void OnDeserializationErrorDefaultImplementation(Exception exception, HttpStatusCode httpStatusCode)
            {
                bool suppressDefaultLog = false;
                OnDeserializationError(ref suppressDefaultLog, exception, httpStatusCode);
                if (!suppressDefaultLog)
                    Logger.LogError(exception, "An error occurred while deserializing the {code} response.", httpStatusCode);
            }

            partial void OnDeserializationError(ref bool suppressDefaultLog, Exception exception, HttpStatusCode httpStatusCode);
        }

        partial void FormatProxyOpenaiPathDelete_0(ref string path);

        /// <summary>
        /// Validates the request parameters
        /// </summary>
        /// <param name="path"></param>
        /// <returns></returns>
        private void ValidateProxyOpenaiPathDelete_0(string path)
        {
            if (path == null)
                throw new ArgumentNullException(nameof(path));
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="path"></param>
        private void AfterProxyOpenaiPathDelete_0DefaultImplementation(IProxyOpenaiPathDelete_0ApiResponse apiResponseLocalVar, string path)
        {
            bool suppressDefaultLog = false;
            AfterProxyOpenaiPathDelete_0(ref suppressDefaultLog, apiResponseLocalVar, path);
            if (!suppressDefaultLog)
                Logger.LogInformation("{0,-9} | {1} | {3}", (apiResponseLocalVar.DownloadedAt - apiResponseLocalVar.RequestedAt).TotalSeconds, apiResponseLocalVar.StatusCode, apiResponseLocalVar.Path);
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="suppressDefaultLog"></param>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="path"></param>
        partial void AfterProxyOpenaiPathDelete_0(ref bool suppressDefaultLog, IProxyOpenaiPathDelete_0ApiResponse apiResponseLocalVar, string path);

        /// <summary>
        /// Logs exceptions that occur while retrieving the server response
        /// </summary>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="path"></param>
        private void OnErrorProxyOpenaiPathDelete_0DefaultImplementation(Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, string path)
        {
            bool suppressDefaultLogLocalVar = false;
            OnErrorProxyOpenaiPathDelete_0(ref suppressDefaultLogLocalVar, exceptionLocalVar, pathFormatLocalVar, pathLocalVar, path);
            if (!suppressDefaultLogLocalVar)
                Logger.LogError(exceptionLocalVar, "An error occurred while sending the request to the server.");
        }

        /// <summary>
        /// A partial method that gives developers a way to provide customized exception handling
        /// </summary>
        /// <param name="suppressDefaultLogLocalVar"></param>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="path"></param>
        partial void OnErrorProxyOpenaiPathDelete_0(ref bool suppressDefaultLogLocalVar, Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, string path);

        /// <summary>
        /// Proxy Deprecated: proxy all requests to OpenAI API
        /// </summary>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDelete_0ApiResponse"/>&gt;</returns>
        public async Task<IProxyOpenaiPathDelete_0ApiResponse?> ProxyOpenaiPathDelete_0OrDefaultAsync(string path, System.Threading.CancellationToken cancellationToken = default)
        {
            try
            {
                return await ProxyOpenaiPathDelete_0Async(path, cancellationToken).ConfigureAwait(false);
            }
            catch (Exception)
            {
                return null;
            }
        }

        /// <summary>
        /// Proxy Deprecated: proxy all requests to OpenAI API
        /// </summary>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDelete_0ApiResponse"/>&gt;</returns>
        public async Task<IProxyOpenaiPathDelete_0ApiResponse> ProxyOpenaiPathDelete_0Async(string path, System.Threading.CancellationToken cancellationToken = default)
        {
            UriBuilder uriBuilderLocalVar = new UriBuilder();

            try
            {
                ValidateProxyOpenaiPathDelete_0(path);

                FormatProxyOpenaiPathDelete_0(ref path);

                using (HttpRequestMessage httpRequestMessageLocalVar = new HttpRequestMessage())
                {
                    uriBuilderLocalVar.Host = HttpClient.BaseAddress!.Host;
                    uriBuilderLocalVar.Port = HttpClient.BaseAddress.Port;
                    uriBuilderLocalVar.Scheme = HttpClient.BaseAddress.Scheme;
                    uriBuilderLocalVar.Path = HttpClient.BaseAddress.AbsolutePath == "/"
                        ? "/openai/{path}"
                        : string.Concat(HttpClient.BaseAddress.AbsolutePath, "/openai/{path}");
                    uriBuilderLocalVar.Path = uriBuilderLocalVar.Path.Replace("%7Bpath%7D", Uri.EscapeDataString(path.ToString()));

                    List<TokenBase> tokenBaseLocalVars = new List<TokenBase>();
                    httpRequestMessageLocalVar.RequestUri = uriBuilderLocalVar.Uri;

                    BearerToken bearerTokenLocalVar1 = (BearerToken) await BearerTokenProvider.GetAsync(cancellation: cancellationToken).ConfigureAwait(false);

                    tokenBaseLocalVars.Add(bearerTokenLocalVar1);

                    bearerTokenLocalVar1.UseInHeader(httpRequestMessageLocalVar, "");

                    string[] acceptLocalVars = new string[] {
                        "application/json"
                    };

                    string? acceptLocalVar = ClientUtils.SelectHeaderAccept(acceptLocalVars);

                    if (acceptLocalVar != null)
                        httpRequestMessageLocalVar.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(acceptLocalVar));

                    httpRequestMessageLocalVar.Method = HttpMethod.Put;

                    DateTime requestedAtLocalVar = DateTime.UtcNow;

                    using (HttpResponseMessage httpResponseMessageLocalVar = await HttpClient.SendAsync(httpRequestMessageLocalVar, cancellationToken).ConfigureAwait(false))
                    {
                        string responseContentLocalVar = await httpResponseMessageLocalVar.Content.ReadAsStringAsync(cancellationToken).ConfigureAwait(false);

                        ILogger<ProxyOpenaiPathDelete_0ApiResponse> apiResponseLoggerLocalVar = LoggerFactory.CreateLogger<ProxyOpenaiPathDelete_0ApiResponse>();

                        ProxyOpenaiPathDelete_0ApiResponse apiResponseLocalVar = new(apiResponseLoggerLocalVar, httpRequestMessageLocalVar, httpResponseMessageLocalVar, responseContentLocalVar, "/openai/{path}", requestedAtLocalVar, _jsonSerializerOptions);

                        AfterProxyOpenaiPathDelete_0DefaultImplementation(apiResponseLocalVar, path);

                        Events.ExecuteOnProxyOpenaiPathDelete_0(apiResponseLocalVar);

                        if (apiResponseLocalVar.StatusCode == (HttpStatusCode) 429)
                            foreach(TokenBase tokenBaseLocalVar in tokenBaseLocalVars)
                                tokenBaseLocalVar.BeginRateLimit();

                        return apiResponseLocalVar;
                    }
                }
            }
            catch(Exception e)
            {
                OnErrorProxyOpenaiPathDelete_0DefaultImplementation(e, "/openai/{path}", uriBuilderLocalVar.Path, path);
                Events.ExecuteOnErrorProxyOpenaiPathDelete_0(e);
                throw;
            }
        }

        /// <summary>
        /// The <see cref="ProxyOpenaiPathDelete_0ApiResponse"/>
        /// </summary>
        public partial class ProxyOpenaiPathDelete_0ApiResponse : Org.OpenAPITools.Client.ApiResponse, IProxyOpenaiPathDelete_0ApiResponse
        {
            /// <summary>
            /// The logger
            /// </summary>
            public ILogger<ProxyOpenaiPathDelete_0ApiResponse> Logger { get; }

            /// <summary>
            /// The <see cref="ProxyOpenaiPathDelete_0ApiResponse"/>
            /// </summary>
            /// <param name="logger"></param>
            /// <param name="httpRequestMessage"></param>
            /// <param name="httpResponseMessage"></param>
            /// <param name="rawContent"></param>
            /// <param name="path"></param>
            /// <param name="requestedAt"></param>
            /// <param name="jsonSerializerOptions"></param>
            public ProxyOpenaiPathDelete_0ApiResponse(ILogger<ProxyOpenaiPathDelete_0ApiResponse> logger, System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage, string rawContent, string path, DateTime requestedAt, System.Text.Json.JsonSerializerOptions jsonSerializerOptions) : base(httpRequestMessage, httpResponseMessage, rawContent, path, requestedAt, jsonSerializerOptions)
            {
                Logger = logger;
                OnCreated(httpRequestMessage, httpResponseMessage);
            }

            partial void OnCreated(global::System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage);

            /// <summary>
            /// Returns true if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public bool IsOk => 200 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public Object? Ok()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsOk
                    ? System.Text.Json.JsonSerializer.Deserialize<Object>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 200 Ok and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryOk([NotNullWhen(true)]out Object? result)
            {
                result = null;

                try
                {
                    result = Ok();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)200);
                }

                return result != null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public bool IsUnprocessableContent => 422 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public Org.OpenAPITools.Model.HTTPValidationError? UnprocessableContent()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsUnprocessableContent
                    ? System.Text.Json.JsonSerializer.Deserialize<Org.OpenAPITools.Model.HTTPValidationError>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryUnprocessableContent([NotNullWhen(true)]out Org.OpenAPITools.Model.HTTPValidationError? result)
            {
                result = null;

                try
                {
                    result = UnprocessableContent();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)422);
                }

                return result != null;
            }

            private void OnDeserializationErrorDefaultImplementation(Exception exception, HttpStatusCode httpStatusCode)
            {
                bool suppressDefaultLog = false;
                OnDeserializationError(ref suppressDefaultLog, exception, httpStatusCode);
                if (!suppressDefaultLog)
                    Logger.LogError(exception, "An error occurred while deserializing the {code} response.", httpStatusCode);
            }

            partial void OnDeserializationError(ref bool suppressDefaultLog, Exception exception, HttpStatusCode httpStatusCode);
        }

        partial void FormatProxyOpenaiPathDelete_1(ref string path);

        /// <summary>
        /// Validates the request parameters
        /// </summary>
        /// <param name="path"></param>
        /// <returns></returns>
        private void ValidateProxyOpenaiPathDelete_1(string path)
        {
            if (path == null)
                throw new ArgumentNullException(nameof(path));
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="path"></param>
        private void AfterProxyOpenaiPathDelete_1DefaultImplementation(IProxyOpenaiPathDelete_1ApiResponse apiResponseLocalVar, string path)
        {
            bool suppressDefaultLog = false;
            AfterProxyOpenaiPathDelete_1(ref suppressDefaultLog, apiResponseLocalVar, path);
            if (!suppressDefaultLog)
                Logger.LogInformation("{0,-9} | {1} | {3}", (apiResponseLocalVar.DownloadedAt - apiResponseLocalVar.RequestedAt).TotalSeconds, apiResponseLocalVar.StatusCode, apiResponseLocalVar.Path);
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="suppressDefaultLog"></param>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="path"></param>
        partial void AfterProxyOpenaiPathDelete_1(ref bool suppressDefaultLog, IProxyOpenaiPathDelete_1ApiResponse apiResponseLocalVar, string path);

        /// <summary>
        /// Logs exceptions that occur while retrieving the server response
        /// </summary>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="path"></param>
        private void OnErrorProxyOpenaiPathDelete_1DefaultImplementation(Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, string path)
        {
            bool suppressDefaultLogLocalVar = false;
            OnErrorProxyOpenaiPathDelete_1(ref suppressDefaultLogLocalVar, exceptionLocalVar, pathFormatLocalVar, pathLocalVar, path);
            if (!suppressDefaultLogLocalVar)
                Logger.LogError(exceptionLocalVar, "An error occurred while sending the request to the server.");
        }

        /// <summary>
        /// A partial method that gives developers a way to provide customized exception handling
        /// </summary>
        /// <param name="suppressDefaultLogLocalVar"></param>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="path"></param>
        partial void OnErrorProxyOpenaiPathDelete_1(ref bool suppressDefaultLogLocalVar, Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, string path);

        /// <summary>
        /// Proxy Deprecated: proxy all requests to OpenAI API
        /// </summary>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDelete_1ApiResponse"/>&gt;</returns>
        public async Task<IProxyOpenaiPathDelete_1ApiResponse?> ProxyOpenaiPathDelete_1OrDefaultAsync(string path, System.Threading.CancellationToken cancellationToken = default)
        {
            try
            {
                return await ProxyOpenaiPathDelete_1Async(path, cancellationToken).ConfigureAwait(false);
            }
            catch (Exception)
            {
                return null;
            }
        }

        /// <summary>
        /// Proxy Deprecated: proxy all requests to OpenAI API
        /// </summary>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDelete_1ApiResponse"/>&gt;</returns>
        public async Task<IProxyOpenaiPathDelete_1ApiResponse> ProxyOpenaiPathDelete_1Async(string path, System.Threading.CancellationToken cancellationToken = default)
        {
            UriBuilder uriBuilderLocalVar = new UriBuilder();

            try
            {
                ValidateProxyOpenaiPathDelete_1(path);

                FormatProxyOpenaiPathDelete_1(ref path);

                using (HttpRequestMessage httpRequestMessageLocalVar = new HttpRequestMessage())
                {
                    uriBuilderLocalVar.Host = HttpClient.BaseAddress!.Host;
                    uriBuilderLocalVar.Port = HttpClient.BaseAddress.Port;
                    uriBuilderLocalVar.Scheme = HttpClient.BaseAddress.Scheme;
                    uriBuilderLocalVar.Path = HttpClient.BaseAddress.AbsolutePath == "/"
                        ? "/openai/{path}"
                        : string.Concat(HttpClient.BaseAddress.AbsolutePath, "/openai/{path}");
                    uriBuilderLocalVar.Path = uriBuilderLocalVar.Path.Replace("%7Bpath%7D", Uri.EscapeDataString(path.ToString()));

                    List<TokenBase> tokenBaseLocalVars = new List<TokenBase>();
                    httpRequestMessageLocalVar.RequestUri = uriBuilderLocalVar.Uri;

                    BearerToken bearerTokenLocalVar1 = (BearerToken) await BearerTokenProvider.GetAsync(cancellation: cancellationToken).ConfigureAwait(false);

                    tokenBaseLocalVars.Add(bearerTokenLocalVar1);

                    bearerTokenLocalVar1.UseInHeader(httpRequestMessageLocalVar, "");

                    string[] acceptLocalVars = new string[] {
                        "application/json"
                    };

                    string? acceptLocalVar = ClientUtils.SelectHeaderAccept(acceptLocalVars);

                    if (acceptLocalVar != null)
                        httpRequestMessageLocalVar.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(acceptLocalVar));

                    httpRequestMessageLocalVar.Method = HttpMethod.Post;

                    DateTime requestedAtLocalVar = DateTime.UtcNow;

                    using (HttpResponseMessage httpResponseMessageLocalVar = await HttpClient.SendAsync(httpRequestMessageLocalVar, cancellationToken).ConfigureAwait(false))
                    {
                        string responseContentLocalVar = await httpResponseMessageLocalVar.Content.ReadAsStringAsync(cancellationToken).ConfigureAwait(false);

                        ILogger<ProxyOpenaiPathDelete_1ApiResponse> apiResponseLoggerLocalVar = LoggerFactory.CreateLogger<ProxyOpenaiPathDelete_1ApiResponse>();

                        ProxyOpenaiPathDelete_1ApiResponse apiResponseLocalVar = new(apiResponseLoggerLocalVar, httpRequestMessageLocalVar, httpResponseMessageLocalVar, responseContentLocalVar, "/openai/{path}", requestedAtLocalVar, _jsonSerializerOptions);

                        AfterProxyOpenaiPathDelete_1DefaultImplementation(apiResponseLocalVar, path);

                        Events.ExecuteOnProxyOpenaiPathDelete_1(apiResponseLocalVar);

                        if (apiResponseLocalVar.StatusCode == (HttpStatusCode) 429)
                            foreach(TokenBase tokenBaseLocalVar in tokenBaseLocalVars)
                                tokenBaseLocalVar.BeginRateLimit();

                        return apiResponseLocalVar;
                    }
                }
            }
            catch(Exception e)
            {
                OnErrorProxyOpenaiPathDelete_1DefaultImplementation(e, "/openai/{path}", uriBuilderLocalVar.Path, path);
                Events.ExecuteOnErrorProxyOpenaiPathDelete_1(e);
                throw;
            }
        }

        /// <summary>
        /// The <see cref="ProxyOpenaiPathDelete_1ApiResponse"/>
        /// </summary>
        public partial class ProxyOpenaiPathDelete_1ApiResponse : Org.OpenAPITools.Client.ApiResponse, IProxyOpenaiPathDelete_1ApiResponse
        {
            /// <summary>
            /// The logger
            /// </summary>
            public ILogger<ProxyOpenaiPathDelete_1ApiResponse> Logger { get; }

            /// <summary>
            /// The <see cref="ProxyOpenaiPathDelete_1ApiResponse"/>
            /// </summary>
            /// <param name="logger"></param>
            /// <param name="httpRequestMessage"></param>
            /// <param name="httpResponseMessage"></param>
            /// <param name="rawContent"></param>
            /// <param name="path"></param>
            /// <param name="requestedAt"></param>
            /// <param name="jsonSerializerOptions"></param>
            public ProxyOpenaiPathDelete_1ApiResponse(ILogger<ProxyOpenaiPathDelete_1ApiResponse> logger, System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage, string rawContent, string path, DateTime requestedAt, System.Text.Json.JsonSerializerOptions jsonSerializerOptions) : base(httpRequestMessage, httpResponseMessage, rawContent, path, requestedAt, jsonSerializerOptions)
            {
                Logger = logger;
                OnCreated(httpRequestMessage, httpResponseMessage);
            }

            partial void OnCreated(global::System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage);

            /// <summary>
            /// Returns true if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public bool IsOk => 200 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public Object? Ok()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsOk
                    ? System.Text.Json.JsonSerializer.Deserialize<Object>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 200 Ok and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryOk([NotNullWhen(true)]out Object? result)
            {
                result = null;

                try
                {
                    result = Ok();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)200);
                }

                return result != null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public bool IsUnprocessableContent => 422 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public Org.OpenAPITools.Model.HTTPValidationError? UnprocessableContent()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsUnprocessableContent
                    ? System.Text.Json.JsonSerializer.Deserialize<Org.OpenAPITools.Model.HTTPValidationError>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryUnprocessableContent([NotNullWhen(true)]out Org.OpenAPITools.Model.HTTPValidationError? result)
            {
                result = null;

                try
                {
                    result = UnprocessableContent();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)422);
                }

                return result != null;
            }

            private void OnDeserializationErrorDefaultImplementation(Exception exception, HttpStatusCode httpStatusCode)
            {
                bool suppressDefaultLog = false;
                OnDeserializationError(ref suppressDefaultLog, exception, httpStatusCode);
                if (!suppressDefaultLog)
                    Logger.LogError(exception, "An error occurred while deserializing the {code} response.", httpStatusCode);
            }

            partial void OnDeserializationError(ref bool suppressDefaultLog, Exception exception, HttpStatusCode httpStatusCode);
        }

        partial void FormatProxyOpenaiPathDelete_2(ref string path);

        /// <summary>
        /// Validates the request parameters
        /// </summary>
        /// <param name="path"></param>
        /// <returns></returns>
        private void ValidateProxyOpenaiPathDelete_2(string path)
        {
            if (path == null)
                throw new ArgumentNullException(nameof(path));
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="path"></param>
        private void AfterProxyOpenaiPathDelete_2DefaultImplementation(IProxyOpenaiPathDelete_2ApiResponse apiResponseLocalVar, string path)
        {
            bool suppressDefaultLog = false;
            AfterProxyOpenaiPathDelete_2(ref suppressDefaultLog, apiResponseLocalVar, path);
            if (!suppressDefaultLog)
                Logger.LogInformation("{0,-9} | {1} | {3}", (apiResponseLocalVar.DownloadedAt - apiResponseLocalVar.RequestedAt).TotalSeconds, apiResponseLocalVar.StatusCode, apiResponseLocalVar.Path);
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="suppressDefaultLog"></param>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="path"></param>
        partial void AfterProxyOpenaiPathDelete_2(ref bool suppressDefaultLog, IProxyOpenaiPathDelete_2ApiResponse apiResponseLocalVar, string path);

        /// <summary>
        /// Logs exceptions that occur while retrieving the server response
        /// </summary>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="path"></param>
        private void OnErrorProxyOpenaiPathDelete_2DefaultImplementation(Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, string path)
        {
            bool suppressDefaultLogLocalVar = false;
            OnErrorProxyOpenaiPathDelete_2(ref suppressDefaultLogLocalVar, exceptionLocalVar, pathFormatLocalVar, pathLocalVar, path);
            if (!suppressDefaultLogLocalVar)
                Logger.LogError(exceptionLocalVar, "An error occurred while sending the request to the server.");
        }

        /// <summary>
        /// A partial method that gives developers a way to provide customized exception handling
        /// </summary>
        /// <param name="suppressDefaultLogLocalVar"></param>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="path"></param>
        partial void OnErrorProxyOpenaiPathDelete_2(ref bool suppressDefaultLogLocalVar, Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, string path);

        /// <summary>
        /// Proxy Deprecated: proxy all requests to OpenAI API
        /// </summary>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDelete_2ApiResponse"/>&gt;</returns>
        public async Task<IProxyOpenaiPathDelete_2ApiResponse?> ProxyOpenaiPathDelete_2OrDefaultAsync(string path, System.Threading.CancellationToken cancellationToken = default)
        {
            try
            {
                return await ProxyOpenaiPathDelete_2Async(path, cancellationToken).ConfigureAwait(false);
            }
            catch (Exception)
            {
                return null;
            }
        }

        /// <summary>
        /// Proxy Deprecated: proxy all requests to OpenAI API
        /// </summary>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="path"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IProxyOpenaiPathDelete_2ApiResponse"/>&gt;</returns>
        public async Task<IProxyOpenaiPathDelete_2ApiResponse> ProxyOpenaiPathDelete_2Async(string path, System.Threading.CancellationToken cancellationToken = default)
        {
            UriBuilder uriBuilderLocalVar = new UriBuilder();

            try
            {
                ValidateProxyOpenaiPathDelete_2(path);

                FormatProxyOpenaiPathDelete_2(ref path);

                using (HttpRequestMessage httpRequestMessageLocalVar = new HttpRequestMessage())
                {
                    uriBuilderLocalVar.Host = HttpClient.BaseAddress!.Host;
                    uriBuilderLocalVar.Port = HttpClient.BaseAddress.Port;
                    uriBuilderLocalVar.Scheme = HttpClient.BaseAddress.Scheme;
                    uriBuilderLocalVar.Path = HttpClient.BaseAddress.AbsolutePath == "/"
                        ? "/openai/{path}"
                        : string.Concat(HttpClient.BaseAddress.AbsolutePath, "/openai/{path}");
                    uriBuilderLocalVar.Path = uriBuilderLocalVar.Path.Replace("%7Bpath%7D", Uri.EscapeDataString(path.ToString()));

                    List<TokenBase> tokenBaseLocalVars = new List<TokenBase>();
                    httpRequestMessageLocalVar.RequestUri = uriBuilderLocalVar.Uri;

                    BearerToken bearerTokenLocalVar1 = (BearerToken) await BearerTokenProvider.GetAsync(cancellation: cancellationToken).ConfigureAwait(false);

                    tokenBaseLocalVars.Add(bearerTokenLocalVar1);

                    bearerTokenLocalVar1.UseInHeader(httpRequestMessageLocalVar, "");

                    string[] acceptLocalVars = new string[] {
                        "application/json"
                    };

                    string? acceptLocalVar = ClientUtils.SelectHeaderAccept(acceptLocalVars);

                    if (acceptLocalVar != null)
                        httpRequestMessageLocalVar.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(acceptLocalVar));

                    httpRequestMessageLocalVar.Method = HttpMethod.Delete;

                    DateTime requestedAtLocalVar = DateTime.UtcNow;

                    using (HttpResponseMessage httpResponseMessageLocalVar = await HttpClient.SendAsync(httpRequestMessageLocalVar, cancellationToken).ConfigureAwait(false))
                    {
                        string responseContentLocalVar = await httpResponseMessageLocalVar.Content.ReadAsStringAsync(cancellationToken).ConfigureAwait(false);

                        ILogger<ProxyOpenaiPathDelete_2ApiResponse> apiResponseLoggerLocalVar = LoggerFactory.CreateLogger<ProxyOpenaiPathDelete_2ApiResponse>();

                        ProxyOpenaiPathDelete_2ApiResponse apiResponseLocalVar = new(apiResponseLoggerLocalVar, httpRequestMessageLocalVar, httpResponseMessageLocalVar, responseContentLocalVar, "/openai/{path}", requestedAtLocalVar, _jsonSerializerOptions);

                        AfterProxyOpenaiPathDelete_2DefaultImplementation(apiResponseLocalVar, path);

                        Events.ExecuteOnProxyOpenaiPathDelete_2(apiResponseLocalVar);

                        if (apiResponseLocalVar.StatusCode == (HttpStatusCode) 429)
                            foreach(TokenBase tokenBaseLocalVar in tokenBaseLocalVars)
                                tokenBaseLocalVar.BeginRateLimit();

                        return apiResponseLocalVar;
                    }
                }
            }
            catch(Exception e)
            {
                OnErrorProxyOpenaiPathDelete_2DefaultImplementation(e, "/openai/{path}", uriBuilderLocalVar.Path, path);
                Events.ExecuteOnErrorProxyOpenaiPathDelete_2(e);
                throw;
            }
        }

        /// <summary>
        /// The <see cref="ProxyOpenaiPathDelete_2ApiResponse"/>
        /// </summary>
        public partial class ProxyOpenaiPathDelete_2ApiResponse : Org.OpenAPITools.Client.ApiResponse, IProxyOpenaiPathDelete_2ApiResponse
        {
            /// <summary>
            /// The logger
            /// </summary>
            public ILogger<ProxyOpenaiPathDelete_2ApiResponse> Logger { get; }

            /// <summary>
            /// The <see cref="ProxyOpenaiPathDelete_2ApiResponse"/>
            /// </summary>
            /// <param name="logger"></param>
            /// <param name="httpRequestMessage"></param>
            /// <param name="httpResponseMessage"></param>
            /// <param name="rawContent"></param>
            /// <param name="path"></param>
            /// <param name="requestedAt"></param>
            /// <param name="jsonSerializerOptions"></param>
            public ProxyOpenaiPathDelete_2ApiResponse(ILogger<ProxyOpenaiPathDelete_2ApiResponse> logger, System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage, string rawContent, string path, DateTime requestedAt, System.Text.Json.JsonSerializerOptions jsonSerializerOptions) : base(httpRequestMessage, httpResponseMessage, rawContent, path, requestedAt, jsonSerializerOptions)
            {
                Logger = logger;
                OnCreated(httpRequestMessage, httpResponseMessage);
            }

            partial void OnCreated(global::System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage);

            /// <summary>
            /// Returns true if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public bool IsOk => 200 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public Object? Ok()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsOk
                    ? System.Text.Json.JsonSerializer.Deserialize<Object>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 200 Ok and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryOk([NotNullWhen(true)]out Object? result)
            {
                result = null;

                try
                {
                    result = Ok();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)200);
                }

                return result != null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public bool IsUnprocessableContent => 422 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public Org.OpenAPITools.Model.HTTPValidationError? UnprocessableContent()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsUnprocessableContent
                    ? System.Text.Json.JsonSerializer.Deserialize<Org.OpenAPITools.Model.HTTPValidationError>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryUnprocessableContent([NotNullWhen(true)]out Org.OpenAPITools.Model.HTTPValidationError? result)
            {
                result = null;

                try
                {
                    result = UnprocessableContent();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)422);
                }

                return result != null;
            }

            private void OnDeserializationErrorDefaultImplementation(Exception exception, HttpStatusCode httpStatusCode)
            {
                bool suppressDefaultLog = false;
                OnDeserializationError(ref suppressDefaultLog, exception, httpStatusCode);
                if (!suppressDefaultLog)
                    Logger.LogError(exception, "An error occurred while deserializing the {code} response.", httpStatusCode);
            }

            partial void OnDeserializationError(ref bool suppressDefaultLog, Exception exception, HttpStatusCode httpStatusCode);
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="apiResponseLocalVar"></param>
        private void AfterSpeechOpenaiAudioSpeechPostDefaultImplementation(ISpeechOpenaiAudioSpeechPostApiResponse apiResponseLocalVar)
        {
            bool suppressDefaultLog = false;
            AfterSpeechOpenaiAudioSpeechPost(ref suppressDefaultLog, apiResponseLocalVar);
            if (!suppressDefaultLog)
                Logger.LogInformation("{0,-9} | {1} | {3}", (apiResponseLocalVar.DownloadedAt - apiResponseLocalVar.RequestedAt).TotalSeconds, apiResponseLocalVar.StatusCode, apiResponseLocalVar.Path);
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="suppressDefaultLog"></param>
        /// <param name="apiResponseLocalVar"></param>
        partial void AfterSpeechOpenaiAudioSpeechPost(ref bool suppressDefaultLog, ISpeechOpenaiAudioSpeechPostApiResponse apiResponseLocalVar);

        /// <summary>
        /// Logs exceptions that occur while retrieving the server response
        /// </summary>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        private void OnErrorSpeechOpenaiAudioSpeechPostDefaultImplementation(Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar)
        {
            bool suppressDefaultLogLocalVar = false;
            OnErrorSpeechOpenaiAudioSpeechPost(ref suppressDefaultLogLocalVar, exceptionLocalVar, pathFormatLocalVar, pathLocalVar);
            if (!suppressDefaultLogLocalVar)
                Logger.LogError(exceptionLocalVar, "An error occurred while sending the request to the server.");
        }

        /// <summary>
        /// A partial method that gives developers a way to provide customized exception handling
        /// </summary>
        /// <param name="suppressDefaultLogLocalVar"></param>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        partial void OnErrorSpeechOpenaiAudioSpeechPost(ref bool suppressDefaultLogLocalVar, Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar);

        /// <summary>
        /// Speech 
        /// </summary>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="ISpeechOpenaiAudioSpeechPostApiResponse"/>&gt;</returns>
        public async Task<ISpeechOpenaiAudioSpeechPostApiResponse?> SpeechOpenaiAudioSpeechPostOrDefaultAsync(System.Threading.CancellationToken cancellationToken = default)
        {
            try
            {
                return await SpeechOpenaiAudioSpeechPostAsync(cancellationToken).ConfigureAwait(false);
            }
            catch (Exception)
            {
                return null;
            }
        }

        /// <summary>
        /// Speech 
        /// </summary>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="ISpeechOpenaiAudioSpeechPostApiResponse"/>&gt;</returns>
        public async Task<ISpeechOpenaiAudioSpeechPostApiResponse> SpeechOpenaiAudioSpeechPostAsync(System.Threading.CancellationToken cancellationToken = default)
        {
            UriBuilder uriBuilderLocalVar = new UriBuilder();

            try
            {
                using (HttpRequestMessage httpRequestMessageLocalVar = new HttpRequestMessage())
                {
                    uriBuilderLocalVar.Host = HttpClient.BaseAddress!.Host;
                    uriBuilderLocalVar.Port = HttpClient.BaseAddress.Port;
                    uriBuilderLocalVar.Scheme = HttpClient.BaseAddress.Scheme;
                    uriBuilderLocalVar.Path = HttpClient.BaseAddress.AbsolutePath == "/"
                        ? "/openai/audio/speech"
                        : string.Concat(HttpClient.BaseAddress.AbsolutePath, "/openai/audio/speech");

                    List<TokenBase> tokenBaseLocalVars = new List<TokenBase>();
                    httpRequestMessageLocalVar.RequestUri = uriBuilderLocalVar.Uri;

                    BearerToken bearerTokenLocalVar1 = (BearerToken) await BearerTokenProvider.GetAsync(cancellation: cancellationToken).ConfigureAwait(false);

                    tokenBaseLocalVars.Add(bearerTokenLocalVar1);

                    bearerTokenLocalVar1.UseInHeader(httpRequestMessageLocalVar, "");

                    string[] acceptLocalVars = new string[] {
                        "application/json"
                    };

                    string? acceptLocalVar = ClientUtils.SelectHeaderAccept(acceptLocalVars);

                    if (acceptLocalVar != null)
                        httpRequestMessageLocalVar.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(acceptLocalVar));

                    httpRequestMessageLocalVar.Method = HttpMethod.Post;

                    DateTime requestedAtLocalVar = DateTime.UtcNow;

                    using (HttpResponseMessage httpResponseMessageLocalVar = await HttpClient.SendAsync(httpRequestMessageLocalVar, cancellationToken).ConfigureAwait(false))
                    {
                        string responseContentLocalVar = await httpResponseMessageLocalVar.Content.ReadAsStringAsync(cancellationToken).ConfigureAwait(false);

                        ILogger<SpeechOpenaiAudioSpeechPostApiResponse> apiResponseLoggerLocalVar = LoggerFactory.CreateLogger<SpeechOpenaiAudioSpeechPostApiResponse>();

                        SpeechOpenaiAudioSpeechPostApiResponse apiResponseLocalVar = new(apiResponseLoggerLocalVar, httpRequestMessageLocalVar, httpResponseMessageLocalVar, responseContentLocalVar, "/openai/audio/speech", requestedAtLocalVar, _jsonSerializerOptions);

                        AfterSpeechOpenaiAudioSpeechPostDefaultImplementation(apiResponseLocalVar);

                        Events.ExecuteOnSpeechOpenaiAudioSpeechPost(apiResponseLocalVar);

                        if (apiResponseLocalVar.StatusCode == (HttpStatusCode) 429)
                            foreach(TokenBase tokenBaseLocalVar in tokenBaseLocalVars)
                                tokenBaseLocalVar.BeginRateLimit();

                        return apiResponseLocalVar;
                    }
                }
            }
            catch(Exception e)
            {
                OnErrorSpeechOpenaiAudioSpeechPostDefaultImplementation(e, "/openai/audio/speech", uriBuilderLocalVar.Path);
                Events.ExecuteOnErrorSpeechOpenaiAudioSpeechPost(e);
                throw;
            }
        }

        /// <summary>
        /// The <see cref="SpeechOpenaiAudioSpeechPostApiResponse"/>
        /// </summary>
        public partial class SpeechOpenaiAudioSpeechPostApiResponse : Org.OpenAPITools.Client.ApiResponse, ISpeechOpenaiAudioSpeechPostApiResponse
        {
            /// <summary>
            /// The logger
            /// </summary>
            public ILogger<SpeechOpenaiAudioSpeechPostApiResponse> Logger { get; }

            /// <summary>
            /// The <see cref="SpeechOpenaiAudioSpeechPostApiResponse"/>
            /// </summary>
            /// <param name="logger"></param>
            /// <param name="httpRequestMessage"></param>
            /// <param name="httpResponseMessage"></param>
            /// <param name="rawContent"></param>
            /// <param name="path"></param>
            /// <param name="requestedAt"></param>
            /// <param name="jsonSerializerOptions"></param>
            public SpeechOpenaiAudioSpeechPostApiResponse(ILogger<SpeechOpenaiAudioSpeechPostApiResponse> logger, System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage, string rawContent, string path, DateTime requestedAt, System.Text.Json.JsonSerializerOptions jsonSerializerOptions) : base(httpRequestMessage, httpResponseMessage, rawContent, path, requestedAt, jsonSerializerOptions)
            {
                Logger = logger;
                OnCreated(httpRequestMessage, httpResponseMessage);
            }

            partial void OnCreated(global::System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage);

            /// <summary>
            /// Returns true if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public bool IsOk => 200 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public Object? Ok()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsOk
                    ? System.Text.Json.JsonSerializer.Deserialize<Object>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 200 Ok and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryOk([NotNullWhen(true)]out Object? result)
            {
                result = null;

                try
                {
                    result = Ok();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)200);
                }

                return result != null;
            }

            private void OnDeserializationErrorDefaultImplementation(Exception exception, HttpStatusCode httpStatusCode)
            {
                bool suppressDefaultLog = false;
                OnDeserializationError(ref suppressDefaultLog, exception, httpStatusCode);
                if (!suppressDefaultLog)
                    Logger.LogError(exception, "An error occurred while deserializing the {code} response.", httpStatusCode);
            }

            partial void OnDeserializationError(ref bool suppressDefaultLog, Exception exception, HttpStatusCode httpStatusCode);
        }

        partial void FormatUpdateConfigOpenaiConfigUpdatePost(OpenWebuiRoutersOpenaiOpenAIConfigForm openWebuiRoutersOpenaiOpenAIConfigForm);

        /// <summary>
        /// Validates the request parameters
        /// </summary>
        /// <param name="openWebuiRoutersOpenaiOpenAIConfigForm"></param>
        /// <returns></returns>
        private void ValidateUpdateConfigOpenaiConfigUpdatePost(OpenWebuiRoutersOpenaiOpenAIConfigForm openWebuiRoutersOpenaiOpenAIConfigForm)
        {
            if (openWebuiRoutersOpenaiOpenAIConfigForm == null)
                throw new ArgumentNullException(nameof(openWebuiRoutersOpenaiOpenAIConfigForm));
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="openWebuiRoutersOpenaiOpenAIConfigForm"></param>
        private void AfterUpdateConfigOpenaiConfigUpdatePostDefaultImplementation(IUpdateConfigOpenaiConfigUpdatePostApiResponse apiResponseLocalVar, OpenWebuiRoutersOpenaiOpenAIConfigForm openWebuiRoutersOpenaiOpenAIConfigForm)
        {
            bool suppressDefaultLog = false;
            AfterUpdateConfigOpenaiConfigUpdatePost(ref suppressDefaultLog, apiResponseLocalVar, openWebuiRoutersOpenaiOpenAIConfigForm);
            if (!suppressDefaultLog)
                Logger.LogInformation("{0,-9} | {1} | {3}", (apiResponseLocalVar.DownloadedAt - apiResponseLocalVar.RequestedAt).TotalSeconds, apiResponseLocalVar.StatusCode, apiResponseLocalVar.Path);
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="suppressDefaultLog"></param>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="openWebuiRoutersOpenaiOpenAIConfigForm"></param>
        partial void AfterUpdateConfigOpenaiConfigUpdatePost(ref bool suppressDefaultLog, IUpdateConfigOpenaiConfigUpdatePostApiResponse apiResponseLocalVar, OpenWebuiRoutersOpenaiOpenAIConfigForm openWebuiRoutersOpenaiOpenAIConfigForm);

        /// <summary>
        /// Logs exceptions that occur while retrieving the server response
        /// </summary>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="openWebuiRoutersOpenaiOpenAIConfigForm"></param>
        private void OnErrorUpdateConfigOpenaiConfigUpdatePostDefaultImplementation(Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, OpenWebuiRoutersOpenaiOpenAIConfigForm openWebuiRoutersOpenaiOpenAIConfigForm)
        {
            bool suppressDefaultLogLocalVar = false;
            OnErrorUpdateConfigOpenaiConfigUpdatePost(ref suppressDefaultLogLocalVar, exceptionLocalVar, pathFormatLocalVar, pathLocalVar, openWebuiRoutersOpenaiOpenAIConfigForm);
            if (!suppressDefaultLogLocalVar)
                Logger.LogError(exceptionLocalVar, "An error occurred while sending the request to the server.");
        }

        /// <summary>
        /// A partial method that gives developers a way to provide customized exception handling
        /// </summary>
        /// <param name="suppressDefaultLogLocalVar"></param>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="openWebuiRoutersOpenaiOpenAIConfigForm"></param>
        partial void OnErrorUpdateConfigOpenaiConfigUpdatePost(ref bool suppressDefaultLogLocalVar, Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, OpenWebuiRoutersOpenaiOpenAIConfigForm openWebuiRoutersOpenaiOpenAIConfigForm);

        /// <summary>
        /// Update Config 
        /// </summary>
        /// <param name="openWebuiRoutersOpenaiOpenAIConfigForm"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IUpdateConfigOpenaiConfigUpdatePostApiResponse"/>&gt;</returns>
        public async Task<IUpdateConfigOpenaiConfigUpdatePostApiResponse?> UpdateConfigOpenaiConfigUpdatePostOrDefaultAsync(OpenWebuiRoutersOpenaiOpenAIConfigForm openWebuiRoutersOpenaiOpenAIConfigForm, System.Threading.CancellationToken cancellationToken = default)
        {
            try
            {
                return await UpdateConfigOpenaiConfigUpdatePostAsync(openWebuiRoutersOpenaiOpenAIConfigForm, cancellationToken).ConfigureAwait(false);
            }
            catch (Exception)
            {
                return null;
            }
        }

        /// <summary>
        /// Update Config 
        /// </summary>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="openWebuiRoutersOpenaiOpenAIConfigForm"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IUpdateConfigOpenaiConfigUpdatePostApiResponse"/>&gt;</returns>
        public async Task<IUpdateConfigOpenaiConfigUpdatePostApiResponse> UpdateConfigOpenaiConfigUpdatePostAsync(OpenWebuiRoutersOpenaiOpenAIConfigForm openWebuiRoutersOpenaiOpenAIConfigForm, System.Threading.CancellationToken cancellationToken = default)
        {
            UriBuilder uriBuilderLocalVar = new UriBuilder();

            try
            {
                ValidateUpdateConfigOpenaiConfigUpdatePost(openWebuiRoutersOpenaiOpenAIConfigForm);

                FormatUpdateConfigOpenaiConfigUpdatePost(openWebuiRoutersOpenaiOpenAIConfigForm);

                using (HttpRequestMessage httpRequestMessageLocalVar = new HttpRequestMessage())
                {
                    uriBuilderLocalVar.Host = HttpClient.BaseAddress!.Host;
                    uriBuilderLocalVar.Port = HttpClient.BaseAddress.Port;
                    uriBuilderLocalVar.Scheme = HttpClient.BaseAddress.Scheme;
                    uriBuilderLocalVar.Path = HttpClient.BaseAddress.AbsolutePath == "/"
                        ? "/openai/config/update"
                        : string.Concat(HttpClient.BaseAddress.AbsolutePath, "/openai/config/update");

                    httpRequestMessageLocalVar.Content = (openWebuiRoutersOpenaiOpenAIConfigForm as object) is System.IO.Stream stream
                        ? httpRequestMessageLocalVar.Content = new StreamContent(stream)
                        : httpRequestMessageLocalVar.Content = new StringContent(JsonSerializer.Serialize(openWebuiRoutersOpenaiOpenAIConfigForm, _jsonSerializerOptions));

                    List<TokenBase> tokenBaseLocalVars = new List<TokenBase>();
                    httpRequestMessageLocalVar.RequestUri = uriBuilderLocalVar.Uri;

                    BearerToken bearerTokenLocalVar1 = (BearerToken) await BearerTokenProvider.GetAsync(cancellation: cancellationToken).ConfigureAwait(false);

                    tokenBaseLocalVars.Add(bearerTokenLocalVar1);

                    bearerTokenLocalVar1.UseInHeader(httpRequestMessageLocalVar, "");

                    string[] contentTypes = new string[] {
                        "application/json"
                    };

                    string? contentTypeLocalVar = ClientUtils.SelectHeaderContentType(contentTypes);

                    if (contentTypeLocalVar != null && httpRequestMessageLocalVar.Content != null)
                        httpRequestMessageLocalVar.Content.Headers.ContentType = new MediaTypeHeaderValue(contentTypeLocalVar);

                    string[] acceptLocalVars = new string[] {
                        "application/json"
                    };

                    string? acceptLocalVar = ClientUtils.SelectHeaderAccept(acceptLocalVars);

                    if (acceptLocalVar != null)
                        httpRequestMessageLocalVar.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(acceptLocalVar));

                    httpRequestMessageLocalVar.Method = HttpMethod.Post;

                    DateTime requestedAtLocalVar = DateTime.UtcNow;

                    using (HttpResponseMessage httpResponseMessageLocalVar = await HttpClient.SendAsync(httpRequestMessageLocalVar, cancellationToken).ConfigureAwait(false))
                    {
                        string responseContentLocalVar = await httpResponseMessageLocalVar.Content.ReadAsStringAsync(cancellationToken).ConfigureAwait(false);

                        ILogger<UpdateConfigOpenaiConfigUpdatePostApiResponse> apiResponseLoggerLocalVar = LoggerFactory.CreateLogger<UpdateConfigOpenaiConfigUpdatePostApiResponse>();

                        UpdateConfigOpenaiConfigUpdatePostApiResponse apiResponseLocalVar = new(apiResponseLoggerLocalVar, httpRequestMessageLocalVar, httpResponseMessageLocalVar, responseContentLocalVar, "/openai/config/update", requestedAtLocalVar, _jsonSerializerOptions);

                        AfterUpdateConfigOpenaiConfigUpdatePostDefaultImplementation(apiResponseLocalVar, openWebuiRoutersOpenaiOpenAIConfigForm);

                        Events.ExecuteOnUpdateConfigOpenaiConfigUpdatePost(apiResponseLocalVar);

                        if (apiResponseLocalVar.StatusCode == (HttpStatusCode) 429)
                            foreach(TokenBase tokenBaseLocalVar in tokenBaseLocalVars)
                                tokenBaseLocalVar.BeginRateLimit();

                        return apiResponseLocalVar;
                    }
                }
            }
            catch(Exception e)
            {
                OnErrorUpdateConfigOpenaiConfigUpdatePostDefaultImplementation(e, "/openai/config/update", uriBuilderLocalVar.Path, openWebuiRoutersOpenaiOpenAIConfigForm);
                Events.ExecuteOnErrorUpdateConfigOpenaiConfigUpdatePost(e);
                throw;
            }
        }

        /// <summary>
        /// The <see cref="UpdateConfigOpenaiConfigUpdatePostApiResponse"/>
        /// </summary>
        public partial class UpdateConfigOpenaiConfigUpdatePostApiResponse : Org.OpenAPITools.Client.ApiResponse, IUpdateConfigOpenaiConfigUpdatePostApiResponse
        {
            /// <summary>
            /// The logger
            /// </summary>
            public ILogger<UpdateConfigOpenaiConfigUpdatePostApiResponse> Logger { get; }

            /// <summary>
            /// The <see cref="UpdateConfigOpenaiConfigUpdatePostApiResponse"/>
            /// </summary>
            /// <param name="logger"></param>
            /// <param name="httpRequestMessage"></param>
            /// <param name="httpResponseMessage"></param>
            /// <param name="rawContent"></param>
            /// <param name="path"></param>
            /// <param name="requestedAt"></param>
            /// <param name="jsonSerializerOptions"></param>
            public UpdateConfigOpenaiConfigUpdatePostApiResponse(ILogger<UpdateConfigOpenaiConfigUpdatePostApiResponse> logger, System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage, string rawContent, string path, DateTime requestedAt, System.Text.Json.JsonSerializerOptions jsonSerializerOptions) : base(httpRequestMessage, httpResponseMessage, rawContent, path, requestedAt, jsonSerializerOptions)
            {
                Logger = logger;
                OnCreated(httpRequestMessage, httpResponseMessage);
            }

            partial void OnCreated(global::System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage);

            /// <summary>
            /// Returns true if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public bool IsOk => 200 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public Object? Ok()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsOk
                    ? System.Text.Json.JsonSerializer.Deserialize<Object>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 200 Ok and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryOk([NotNullWhen(true)]out Object? result)
            {
                result = null;

                try
                {
                    result = Ok();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)200);
                }

                return result != null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public bool IsUnprocessableContent => 422 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public Org.OpenAPITools.Model.HTTPValidationError? UnprocessableContent()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsUnprocessableContent
                    ? System.Text.Json.JsonSerializer.Deserialize<Org.OpenAPITools.Model.HTTPValidationError>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryUnprocessableContent([NotNullWhen(true)]out Org.OpenAPITools.Model.HTTPValidationError? result)
            {
                result = null;

                try
                {
                    result = UnprocessableContent();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)422);
                }

                return result != null;
            }

            private void OnDeserializationErrorDefaultImplementation(Exception exception, HttpStatusCode httpStatusCode)
            {
                bool suppressDefaultLog = false;
                OnDeserializationError(ref suppressDefaultLog, exception, httpStatusCode);
                if (!suppressDefaultLog)
                    Logger.LogError(exception, "An error occurred while deserializing the {code} response.", httpStatusCode);
            }

            partial void OnDeserializationError(ref bool suppressDefaultLog, Exception exception, HttpStatusCode httpStatusCode);
        }

        partial void FormatVerifyConnectionOpenaiVerifyPost(OpenWebuiRoutersOpenaiConnectionVerificationForm openWebuiRoutersOpenaiConnectionVerificationForm);

        /// <summary>
        /// Validates the request parameters
        /// </summary>
        /// <param name="openWebuiRoutersOpenaiConnectionVerificationForm"></param>
        /// <returns></returns>
        private void ValidateVerifyConnectionOpenaiVerifyPost(OpenWebuiRoutersOpenaiConnectionVerificationForm openWebuiRoutersOpenaiConnectionVerificationForm)
        {
            if (openWebuiRoutersOpenaiConnectionVerificationForm == null)
                throw new ArgumentNullException(nameof(openWebuiRoutersOpenaiConnectionVerificationForm));
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="openWebuiRoutersOpenaiConnectionVerificationForm"></param>
        private void AfterVerifyConnectionOpenaiVerifyPostDefaultImplementation(IVerifyConnectionOpenaiVerifyPostApiResponse apiResponseLocalVar, OpenWebuiRoutersOpenaiConnectionVerificationForm openWebuiRoutersOpenaiConnectionVerificationForm)
        {
            bool suppressDefaultLog = false;
            AfterVerifyConnectionOpenaiVerifyPost(ref suppressDefaultLog, apiResponseLocalVar, openWebuiRoutersOpenaiConnectionVerificationForm);
            if (!suppressDefaultLog)
                Logger.LogInformation("{0,-9} | {1} | {3}", (apiResponseLocalVar.DownloadedAt - apiResponseLocalVar.RequestedAt).TotalSeconds, apiResponseLocalVar.StatusCode, apiResponseLocalVar.Path);
        }

        /// <summary>
        /// Processes the server response
        /// </summary>
        /// <param name="suppressDefaultLog"></param>
        /// <param name="apiResponseLocalVar"></param>
        /// <param name="openWebuiRoutersOpenaiConnectionVerificationForm"></param>
        partial void AfterVerifyConnectionOpenaiVerifyPost(ref bool suppressDefaultLog, IVerifyConnectionOpenaiVerifyPostApiResponse apiResponseLocalVar, OpenWebuiRoutersOpenaiConnectionVerificationForm openWebuiRoutersOpenaiConnectionVerificationForm);

        /// <summary>
        /// Logs exceptions that occur while retrieving the server response
        /// </summary>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="openWebuiRoutersOpenaiConnectionVerificationForm"></param>
        private void OnErrorVerifyConnectionOpenaiVerifyPostDefaultImplementation(Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, OpenWebuiRoutersOpenaiConnectionVerificationForm openWebuiRoutersOpenaiConnectionVerificationForm)
        {
            bool suppressDefaultLogLocalVar = false;
            OnErrorVerifyConnectionOpenaiVerifyPost(ref suppressDefaultLogLocalVar, exceptionLocalVar, pathFormatLocalVar, pathLocalVar, openWebuiRoutersOpenaiConnectionVerificationForm);
            if (!suppressDefaultLogLocalVar)
                Logger.LogError(exceptionLocalVar, "An error occurred while sending the request to the server.");
        }

        /// <summary>
        /// A partial method that gives developers a way to provide customized exception handling
        /// </summary>
        /// <param name="suppressDefaultLogLocalVar"></param>
        /// <param name="exceptionLocalVar"></param>
        /// <param name="pathFormatLocalVar"></param>
        /// <param name="pathLocalVar"></param>
        /// <param name="openWebuiRoutersOpenaiConnectionVerificationForm"></param>
        partial void OnErrorVerifyConnectionOpenaiVerifyPost(ref bool suppressDefaultLogLocalVar, Exception exceptionLocalVar, string pathFormatLocalVar, string pathLocalVar, OpenWebuiRoutersOpenaiConnectionVerificationForm openWebuiRoutersOpenaiConnectionVerificationForm);

        /// <summary>
        /// Verify Connection 
        /// </summary>
        /// <param name="openWebuiRoutersOpenaiConnectionVerificationForm"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IVerifyConnectionOpenaiVerifyPostApiResponse"/>&gt;</returns>
        public async Task<IVerifyConnectionOpenaiVerifyPostApiResponse?> VerifyConnectionOpenaiVerifyPostOrDefaultAsync(OpenWebuiRoutersOpenaiConnectionVerificationForm openWebuiRoutersOpenaiConnectionVerificationForm, System.Threading.CancellationToken cancellationToken = default)
        {
            try
            {
                return await VerifyConnectionOpenaiVerifyPostAsync(openWebuiRoutersOpenaiConnectionVerificationForm, cancellationToken).ConfigureAwait(false);
            }
            catch (Exception)
            {
                return null;
            }
        }

        /// <summary>
        /// Verify Connection 
        /// </summary>
        /// <exception cref="ApiException">Thrown when fails to make API call</exception>
        /// <param name="openWebuiRoutersOpenaiConnectionVerificationForm"></param>
        /// <param name="cancellationToken">Cancellation Token to cancel the request.</param>
        /// <returns><see cref="Task"/>&lt;<see cref="IVerifyConnectionOpenaiVerifyPostApiResponse"/>&gt;</returns>
        public async Task<IVerifyConnectionOpenaiVerifyPostApiResponse> VerifyConnectionOpenaiVerifyPostAsync(OpenWebuiRoutersOpenaiConnectionVerificationForm openWebuiRoutersOpenaiConnectionVerificationForm, System.Threading.CancellationToken cancellationToken = default)
        {
            UriBuilder uriBuilderLocalVar = new UriBuilder();

            try
            {
                ValidateVerifyConnectionOpenaiVerifyPost(openWebuiRoutersOpenaiConnectionVerificationForm);

                FormatVerifyConnectionOpenaiVerifyPost(openWebuiRoutersOpenaiConnectionVerificationForm);

                using (HttpRequestMessage httpRequestMessageLocalVar = new HttpRequestMessage())
                {
                    uriBuilderLocalVar.Host = HttpClient.BaseAddress!.Host;
                    uriBuilderLocalVar.Port = HttpClient.BaseAddress.Port;
                    uriBuilderLocalVar.Scheme = HttpClient.BaseAddress.Scheme;
                    uriBuilderLocalVar.Path = HttpClient.BaseAddress.AbsolutePath == "/"
                        ? "/openai/verify"
                        : string.Concat(HttpClient.BaseAddress.AbsolutePath, "/openai/verify");

                    httpRequestMessageLocalVar.Content = (openWebuiRoutersOpenaiConnectionVerificationForm as object) is System.IO.Stream stream
                        ? httpRequestMessageLocalVar.Content = new StreamContent(stream)
                        : httpRequestMessageLocalVar.Content = new StringContent(JsonSerializer.Serialize(openWebuiRoutersOpenaiConnectionVerificationForm, _jsonSerializerOptions));

                    List<TokenBase> tokenBaseLocalVars = new List<TokenBase>();
                    httpRequestMessageLocalVar.RequestUri = uriBuilderLocalVar.Uri;

                    BearerToken bearerTokenLocalVar1 = (BearerToken) await BearerTokenProvider.GetAsync(cancellation: cancellationToken).ConfigureAwait(false);

                    tokenBaseLocalVars.Add(bearerTokenLocalVar1);

                    bearerTokenLocalVar1.UseInHeader(httpRequestMessageLocalVar, "");

                    string[] contentTypes = new string[] {
                        "application/json"
                    };

                    string? contentTypeLocalVar = ClientUtils.SelectHeaderContentType(contentTypes);

                    if (contentTypeLocalVar != null && httpRequestMessageLocalVar.Content != null)
                        httpRequestMessageLocalVar.Content.Headers.ContentType = new MediaTypeHeaderValue(contentTypeLocalVar);

                    string[] acceptLocalVars = new string[] {
                        "application/json"
                    };

                    string? acceptLocalVar = ClientUtils.SelectHeaderAccept(acceptLocalVars);

                    if (acceptLocalVar != null)
                        httpRequestMessageLocalVar.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(acceptLocalVar));

                    httpRequestMessageLocalVar.Method = HttpMethod.Post;

                    DateTime requestedAtLocalVar = DateTime.UtcNow;

                    using (HttpResponseMessage httpResponseMessageLocalVar = await HttpClient.SendAsync(httpRequestMessageLocalVar, cancellationToken).ConfigureAwait(false))
                    {
                        string responseContentLocalVar = await httpResponseMessageLocalVar.Content.ReadAsStringAsync(cancellationToken).ConfigureAwait(false);

                        ILogger<VerifyConnectionOpenaiVerifyPostApiResponse> apiResponseLoggerLocalVar = LoggerFactory.CreateLogger<VerifyConnectionOpenaiVerifyPostApiResponse>();

                        VerifyConnectionOpenaiVerifyPostApiResponse apiResponseLocalVar = new(apiResponseLoggerLocalVar, httpRequestMessageLocalVar, httpResponseMessageLocalVar, responseContentLocalVar, "/openai/verify", requestedAtLocalVar, _jsonSerializerOptions);

                        AfterVerifyConnectionOpenaiVerifyPostDefaultImplementation(apiResponseLocalVar, openWebuiRoutersOpenaiConnectionVerificationForm);

                        Events.ExecuteOnVerifyConnectionOpenaiVerifyPost(apiResponseLocalVar);

                        if (apiResponseLocalVar.StatusCode == (HttpStatusCode) 429)
                            foreach(TokenBase tokenBaseLocalVar in tokenBaseLocalVars)
                                tokenBaseLocalVar.BeginRateLimit();

                        return apiResponseLocalVar;
                    }
                }
            }
            catch(Exception e)
            {
                OnErrorVerifyConnectionOpenaiVerifyPostDefaultImplementation(e, "/openai/verify", uriBuilderLocalVar.Path, openWebuiRoutersOpenaiConnectionVerificationForm);
                Events.ExecuteOnErrorVerifyConnectionOpenaiVerifyPost(e);
                throw;
            }
        }

        /// <summary>
        /// The <see cref="VerifyConnectionOpenaiVerifyPostApiResponse"/>
        /// </summary>
        public partial class VerifyConnectionOpenaiVerifyPostApiResponse : Org.OpenAPITools.Client.ApiResponse, IVerifyConnectionOpenaiVerifyPostApiResponse
        {
            /// <summary>
            /// The logger
            /// </summary>
            public ILogger<VerifyConnectionOpenaiVerifyPostApiResponse> Logger { get; }

            /// <summary>
            /// The <see cref="VerifyConnectionOpenaiVerifyPostApiResponse"/>
            /// </summary>
            /// <param name="logger"></param>
            /// <param name="httpRequestMessage"></param>
            /// <param name="httpResponseMessage"></param>
            /// <param name="rawContent"></param>
            /// <param name="path"></param>
            /// <param name="requestedAt"></param>
            /// <param name="jsonSerializerOptions"></param>
            public VerifyConnectionOpenaiVerifyPostApiResponse(ILogger<VerifyConnectionOpenaiVerifyPostApiResponse> logger, System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage, string rawContent, string path, DateTime requestedAt, System.Text.Json.JsonSerializerOptions jsonSerializerOptions) : base(httpRequestMessage, httpResponseMessage, rawContent, path, requestedAt, jsonSerializerOptions)
            {
                Logger = logger;
                OnCreated(httpRequestMessage, httpResponseMessage);
            }

            partial void OnCreated(global::System.Net.Http.HttpRequestMessage httpRequestMessage, System.Net.Http.HttpResponseMessage httpResponseMessage);

            /// <summary>
            /// Returns true if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public bool IsOk => 200 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 200 Ok
            /// </summary>
            /// <returns></returns>
            public Object? Ok()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsOk
                    ? System.Text.Json.JsonSerializer.Deserialize<Object>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 200 Ok and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryOk([NotNullWhen(true)]out Object? result)
            {
                result = null;

                try
                {
                    result = Ok();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)200);
                }

                return result != null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public bool IsUnprocessableContent => 422 == (int)StatusCode;

            /// <summary>
            /// Deserializes the response if the response is 422 UnprocessableContent
            /// </summary>
            /// <returns></returns>
            public Org.OpenAPITools.Model.HTTPValidationError? UnprocessableContent()
            {
                // This logic may be modified with the AsModel.mustache template
                return IsUnprocessableContent
                    ? System.Text.Json.JsonSerializer.Deserialize<Org.OpenAPITools.Model.HTTPValidationError>(RawContent, _jsonSerializerOptions)
                    : null;
            }

            /// <summary>
            /// Returns true if the response is 422 UnprocessableContent and the deserialized response is not null
            /// </summary>
            /// <param name="result"></param>
            /// <returns></returns>
            public bool TryUnprocessableContent([NotNullWhen(true)]out Org.OpenAPITools.Model.HTTPValidationError? result)
            {
                result = null;

                try
                {
                    result = UnprocessableContent();
                } catch (Exception e)
                {
                    OnDeserializationErrorDefaultImplementation(e, (HttpStatusCode)422);
                }

                return result != null;
            }

            private void OnDeserializationErrorDefaultImplementation(Exception exception, HttpStatusCode httpStatusCode)
            {
                bool suppressDefaultLog = false;
                OnDeserializationError(ref suppressDefaultLog, exception, httpStatusCode);
                if (!suppressDefaultLog)
                    Logger.LogError(exception, "An error occurred while deserializing the {code} response.", httpStatusCode);
            }

            partial void OnDeserializationError(ref bool suppressDefaultLog, Exception exception, HttpStatusCode httpStatusCode);
        }
    }
}
